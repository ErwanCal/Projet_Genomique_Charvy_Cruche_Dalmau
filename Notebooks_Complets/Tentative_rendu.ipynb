{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4468d29f",
   "metadata": {},
   "source": [
    "## Partie Code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81d25d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO # Permet l'import de la fonction parse\n",
    "from Bio.Seq import Seq # Permet la transformation en complémentaire inverse\n",
    "from Bio.SeqIO.QualityIO import FastqGeneralIterator # Permet un parse plus rapide lorsque beaucoup de séquences (fastaq uniquement sinon voir site biopython pour fasta)\n",
    "import functools as ft # Permet de regrouper des listes pour radix sort\n",
    "from collections import Counter # Demander à Erwan\n",
    "\n",
    "from tqdm import tqdm # Permet d'estimer le temps d'éxécution sur un boucle\n",
    "from datetime import datetime # Permet de comparer la vitesse de 2 programmes \n",
    "#%load_ext snakeviz # temps de calcul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d402b8",
   "metadata": {},
   "source": [
    "### Fonctions d'import des données :\n",
    "\n",
    "Complexité des algorithms : linéaire en temps avec le nombre d'éléments à importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee27be11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_DC3(filename) :\n",
    "    \"\"\"\n",
    "    Fonction qui importe depuis un fichier texte la table des suffixes du génome par DC3 et la stocke dans une liste\n",
    "    \"\"\"\n",
    "    filename = \"DC3_save/\" + filename\n",
    "    with open(filename, 'r') as f:\n",
    "        text = f.readline()\n",
    "        data = text.split(\" \")[:-1]\n",
    "        for i in range(len(data)) :\n",
    "            data[i] = int(data[i])\n",
    "        return(data)\n",
    "\n",
    "def genome_import() :\n",
    "    \"\"\"\n",
    "    Fonction qui importe depuis un fichier fasta la séquence du génome dans une liste contenant [\"seq\", \"n°k\"]\n",
    "    \"\"\"\n",
    "    list_genom=[]\n",
    "    for record in SeqIO.parse(\"GCF_000002765.5_GCA_000002765_genomic.fna\",\"fasta\"):\n",
    "        list_genom.append([str(record.seq).upper(),record.description[-14:]]) # attention le marquage est à changer pour la dernière séquence\n",
    "    \n",
    "    return list_genom\n",
    "    \n",
    "def reads_import_cuts(k) :\n",
    "    \"\"\"\n",
    "    Fonction qui importe depuis un fichier fasta les séquences des reads et les coupes en les rangeant\n",
    "    dans une liste contenant [\"seq\", \"nom\", \"n°kmer\"]\n",
    "    \n",
    "    Entrée : k, int : longueur du kmer\n",
    "    \n",
    "    Sortie : list_reads : liste de tous les read découpés en kmers\n",
    "    \"\"\"\n",
    "    list_reads=[]\n",
    "    with open(\"single_Pfal_dat.fq\") as in_handle:\n",
    "        for title, seq, qual in tqdm(FastqGeneralIterator(in_handle), desc = \"Import sequence\"):\n",
    "            i = 1    # Incrémenteur du nombre de k-mer\n",
    "            while len(seq) >= 1 : # On parcoure toute la séquence\n",
    "                if len(seq) > k : # Cas où le k-mer est entier\n",
    "                    list_reads.append([str(seq[0:k]).upper(),title, i])\n",
    "                    i += 1\n",
    "                    seq = seq[k:]\n",
    "                else : # Cas où le dernier k-mer n'est pas entier\n",
    "                    list_reads.append([str(seq).upper(),title, i])\n",
    "                    seq = \"\"\n",
    "            \n",
    "    return list_reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99e14e4",
   "metadata": {},
   "source": [
    "### Fonction pour la table des suffixes (DC3)\n",
    "\n",
    "Complexité des algorithms : linéaire avec la longueur de la séquence pour DC3 et avec la taille de la liste pour les autres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd68c649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(arr):\n",
    "    \"\"\"\n",
    "    Nécessaire pour le radix sort, je te le laisse Erwan\n",
    "    \"\"\"\n",
    "    return ft.reduce(lambda x, y: x + y, arr)\n",
    "\n",
    "def counting_sort(array,digit,p): \n",
    "    \"\"\"\n",
    "    Nécessaire pour le radix sort, je te le laisse Erwan\n",
    "    \"\"\"\n",
    "    ##The counting sort is a stable sort used in the radic sort\n",
    "    ##here the counting sort needs to be adapted to look at only one digit of each number (for radix)\n",
    "    ##we also added the parameter p to be able to read the triplets (more info below)\n",
    "    ##1) since we only sort single digits, the max will always be smaller than 10\n",
    "    ##2) create count index (that will have the cumulative index in the end)\n",
    "    count_list = [[]for i in range(10)]\n",
    "    for tpl in array :\n",
    "        n_uplet = tpl[0]##we take the first element of the tuple, the n-uplet\n",
    "        num = n_uplet[p] // digit ##we cut off the digits to the right by getting the quotient of the euclidian division\n",
    "        ##p is the index of the number studied in the triplet\n",
    "        count_list[num%10].append(tpl)##we cut off the digits to the left by getting the remainder of the euclidian division\n",
    "    arr_ord = flatten(count_list)\n",
    "\n",
    "    for i in range(len(array)):##we change the base array to allow the radix sort to loop easily\n",
    "        array[i] = arr_ord[i]\n",
    "        \n",
    "def radix_sort(array,p):\n",
    "    \"\"\"\n",
    "    Prend en entrée un tableau de valeur de valeur et le trie en foncion de la première composante\n",
    "    selon l'algorithm du radix sort\n",
    "    \n",
    "    Entrée : array à trier\n",
    "             p : nombre de cases à trier p-uplets\n",
    "    \n",
    "    Sortie : array trié\n",
    "    \"\"\"\n",
    "    ##Here the radix sort is modified to work with the triplet list sent by the DC3\n",
    "    ##The code is not flexible enough to compute all characters in the ascii table, but it's enough for the use needed\n",
    "    ##1) we search for the max in the nuplets\n",
    "    mx = (max(array)[0])[0]+1\n",
    "    if p != 3 : ##we take max = 100 because A T C G are all below 100 in ascii code\n",
    "        for tpl in array:\n",
    "            n_uplet = tpl[0]\n",
    "            if n_uplet[-1] > mx :\n",
    "                mx = n_uplet[-1]+1\n",
    "    '''##2) to know how many loops we have to do, we will use a variable to represent,\n",
    "    the digit we are currently in'''\n",
    "    for i in reversed(range(0,p)):\n",
    "        digit = 1 ##starts at one for units\n",
    "        while mx - digit > 0 :##when all the digits are checked, digit will be greater than the maximum\n",
    "            counting_sort(array,digit,i)\n",
    "            digit *= 10 ##digit will go to the tens, the hundreds, the thousands...\n",
    "            \n",
    "def DC3(S, P_12_base = []) :\n",
    "    \"\"\"\n",
    "    Create the suffix array from DC3 algorithm, could be recursive if needed\n",
    "    \n",
    "    Args:\n",
    "        S (str): string\n",
    "        P_12_base : store P1+2 from recursion to map correctly recursivity\n",
    "    \n",
    "    Return:\n",
    "        index_012 : suffix array of S\n",
    "        order_12 : order of the next recursion to map correctly recursivity\n",
    "    \"\"\"\n",
    "    \n",
    "    DC3_table = np.zeros((3,len(S) + 3), dtype=int) # Les caractères sentinelles sont déja là !\n",
    "    \"\"\"\n",
    "    Table de DC3 qui contient en chaque ligne : \n",
    "    Ligne 0 : indice du caractère\n",
    "    Ligne 1 : conversion du caractère en nombre\n",
    "    Ligne 2 : Ordre de l'indice du caractère\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(len(S) + 3) :\n",
    "            DC3_table[0][i] =  i # On remplace le caractère par son code Ascii\n",
    "    \n",
    "    # String conversion : !!!!! à n'executer que lors de la première récursion !!!!!\n",
    "    if type(S) == str :\n",
    "        S_l = [*S] # On sépare caractère par caractère : \"ATGC\" devient [\"A\",\"T\",\"G\",\"C\"]\n",
    "        for i in range(len(S_l)) :\n",
    "            DC3_table[1][i] =  ord(S_l[i]) # On rempli le caractère par son code Ascii dans la table\n",
    "    else :\n",
    "         for i in range(len(S)) :\n",
    "            DC3_table[1][i] =  S[i] # Cas où l'on rentre dans la boucle une deuxième fois ou plus, pas de conversion\n",
    "    \"\"\"\n",
    "    # Cas où la chaine n'est composé que d'une seule lettre : trivial car DC3 = ordre des indices en décroissant\n",
    "    equal = True\n",
    "    for i in range(len(S)) :\n",
    "        if DC3_table[1][0] != DC3_table[1][i] :\n",
    "            equal = False\n",
    "            break # On teste si la chaine n'est composé que d'une seule lettre\n",
    "    if equal == True :\n",
    "         return [*range(len(S)-1,-1,-1)]\n",
    "    \"\"\"\n",
    "    \n",
    "    # On crée P0, P1, P2 et P1+P2 :    \n",
    "    P0 = [*range(0,len(S)+1,3)] \n",
    "    P1 = [*range(1,len(S)+1,3)]\n",
    "    P2 = [*range(2,len(S)+1,3)]\n",
    "    \n",
    "    P_12 = P1 + P2\n",
    "    \n",
    "\n",
    "    #Obtention des triplets à partir de P1+P2 :\n",
    "    R_12 = []\n",
    "    for val in P_12 :\n",
    "        R_12.append([list(DC3_table[1][val:val+3]), val])\n",
    "    \n",
    "    radix_sort(R_12,3) # On trie les triplets\n",
    "\n",
    "    index_12 = [] # Liste des indexes de R12 trié\n",
    "    order_count = 1 # Compteur pour remplir l'ordre\n",
    "    recur = False # Etat de la récursion tourné True si on a des égalités d'ordre\n",
    "    for j in range(len(R_12)) : # On parcours tous les triplets triés\n",
    "        index_12.append(R_12[j][1]) # ... pour lui attribuer son index depuis P_12\n",
    "        DC3_table[2][R_12[j][1]] = order_count # Et on ajoute l'ordre dans la table\n",
    "        if j < len(R_12)-1 :\n",
    "            if R_12[j][0] != R_12[j+1][0] : # On teste l'égalité des triplets pour mettre l'ordre\n",
    "                order_count += 1\n",
    "            else :\n",
    "                recur = True # On a égalité, donc on doit relancer l'algorithme à la fin des for\n",
    "        else :\n",
    "            order_count += 1\n",
    "\n",
    "    if recur == True :\n",
    "        new_S = [] # On crée T' la séquence des orders suivant l'ordre de P12\n",
    "        for l in P_12 :\n",
    "            new_S.append(DC3_table[2][l])\n",
    "        index_012 = DC3(new_S, P_12) # On doit récupérer ces deux paramètres sinon ça marche pas\n",
    "        index_12 = []\n",
    "        for ind,val in index_012 :\n",
    "            DC3_table[2][ind] = val\n",
    "            index_12.append(ind)\n",
    "    \n",
    "    R_0 = [] # On crée la dernière partie à trier\n",
    "    for val in P0 :\n",
    "        R_0.append([[int(DC3_table[1][val]), DC3_table[2][val + 1]], val]) # On crée R0 avec son indice\n",
    "    \n",
    "    \n",
    "    radix_sort(R_0,2)\n",
    "    \n",
    "    index_0 = [] # Liste des indexes de R0 trié\n",
    "    for k in range(len(R_0)) : # On parcours tous les doublets triés\n",
    "       index_0.append(R_0[k][1]) # On récupère l'indice\n",
    "    \n",
    "    index_012 = [] # On crée l'index final en ordonant 0 et 1,2\n",
    "    i_0 = 0\n",
    "    i_12 = 0\n",
    "    \n",
    "    index_12_dict = {}\n",
    "    for i in range(len(index_12)) :\n",
    "        index_12_dict[index_12[i]] = i\n",
    "    \n",
    "    while (i_0 < len(index_0) and i_12 < len(index_12)) : # On prends tout les éléments : on vide index 0 ou 12\n",
    "        val_i0 = index_0[i_0]\n",
    "        val_i12 = index_12[i_12]\n",
    "        \n",
    "        if DC3_table[1][val_i0] > DC3_table[1][val_i12] : # Cas où index 12 arrive avant index 0\n",
    "            index_012.append(index_12[i_12])\n",
    "            i_12 += 1\n",
    "        elif DC3_table[1][val_i0] < DC3_table[1][val_i12] : # Cas où index 0 arrive avant index 12\n",
    "            index_012.append(index_0[i_0])\n",
    "            i_0 += 1\n",
    "        else : # Cas d'égalité sur l'indice : si les 2 indexes renvoient le même nombre \n",
    "            if index_12[i_12] % 3 == 1 :\n",
    "                if index_12_dict[val_i0 + 1] > index_12_dict[val_i12 + 1] : # Cas où index 12 au deuxième terme arrive avant index 0 au deuxième terme\n",
    "                    index_012.append(index_12[i_12])\n",
    "                    i_12 += 1\n",
    "                else : # Cas où index 0 au deuxième terme arrive avant index 12 au deuxième terme\n",
    "                    index_012.append(index_0[i_0])\n",
    "                    i_0 += 1\n",
    "            else :\n",
    "                if DC3_table[1][val_i0 + 1] > DC3_table[1][val_i12 + 1] : # On teste dabord cas où index 12 + 1 arrive avant index 0 + 1\n",
    "                    index_012.append(index_12[i_12])\n",
    "                    i_12 += 1\n",
    "                elif DC3_table[1][val_i0 + 1] < DC3_table[1][val_i12 + 1] : # Cas où index 0 + 1 arrive avant index 12 + 1\n",
    "                    index_012.append(index_0[i_0])\n",
    "                    i_0 += 1\n",
    "                elif index_12_dict[val_i0 + 2] > index_12_dict[val_i12 + 2] : # Cas où index 12 au deuxième terme arrive avant index 0 au troisième terme\n",
    "                    index_012.append(index_12[i_12])\n",
    "                    i_12 += 1\n",
    "                else : # Cas où index 0 au troisième terme arrive avant index 12 au deuxième terme\n",
    "                    index_012.append(index_0[i_0])\n",
    "                    i_0 += 1\n",
    "    \n",
    "    index_012.extend(index_12[i_12:]) # Si 1 des deux index est encore plein, on ajoute son contenu\n",
    "    index_012.extend(index_0[i_0:])\n",
    "\n",
    "    if int(DC3_table[1][index_012[0]]) == 0 : # On enlève le terme sentinel s'il est présent\n",
    "        index_012 = index_012[1:]\n",
    "\n",
    "    if len(P_12_base) > 0 : # Mapping sur recursion -1 si existe\n",
    "        new_index_012 = []\n",
    "        for n in range(len(index_012)) :\n",
    "            new_index_012.append([P_12_base[index_012[n]], n])\n",
    "        index_012 = new_index_012\n",
    "   \n",
    "\n",
    "    return index_012 # Retourne le suffix array si dernière récursion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51519cc",
   "metadata": {},
   "source": [
    "### Fonctions de mapping :\n",
    "\n",
    "Complexité des algorithms : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8919d6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BWT(text,suffix_table):\n",
    "    \"\"\"\n",
    "    Compute the BWT from the suffix table\n",
    "\n",
    "    Args:\n",
    "        T (str): string\n",
    "        end_of_string (char): end of string character to append\n",
    "\n",
    "    Return:\n",
    "        bwt (str): BWT\n",
    "    \"\"\"\n",
    "    bwt = \"\"\n",
    "    sf_tab = suffix_table\n",
    "    for i in range(len(sf_tab)):\n",
    "        crt = sf_tab[i]\n",
    "        bwt += text[crt-1]\n",
    "    return(bwt)\n",
    "\n",
    "def pattern_matching_BWT(S,pattern,bwt,index,somme):\n",
    "    \"\"\"\n",
    "    Search a pattern in a String using the BWT\n",
    "\n",
    "    Args:\n",
    "        S (str): string\n",
    "        pattern (str): pattern\n",
    "        bwt : the bwt of the text (to not compute it each time)\n",
    "\n",
    "    Return:\n",
    "        bool: true if the pattern is in the string\n",
    "        int : position of the first occurence of the pattern in the ordered text\n",
    "        int : position of the last occurence of the pattern in the ordered text\n",
    "    \"\"\"\n",
    "    pattern_in_S = False\n",
    "    L = list(bwt)\n",
    "    lpattern = list(pattern)\n",
    "    start_string = -1\n",
    "    end_string = -1\n",
    "    e = 0\n",
    "    f = len(L)\n",
    "    ##init des valeurs utiles pour la substring search\n",
    "    i = len(lpattern)-1\n",
    "    X = lpattern[i]\n",
    "    for tpl in somme :\n",
    "        if tpl[0]<X:\n",
    "            e = tpl[1]+1 ##donne place du premier char dans la liste ordonnée\n",
    "        if tpl[0]==X:\n",
    "            f = tpl[1]-1 ##donne place du dernier char\n",
    "\n",
    "    while e < f and i > 0 :\n",
    "        X = lpattern[i]\n",
    "        Y = lpattern[i-1]\n",
    "        suite_impos = True\n",
    "        r = e\n",
    "        s = f\n",
    "        for u in range(r,s+1):\n",
    "            if(suite_impos==False):##we use the boolean to exit the loop early\n",
    "                break\n",
    "            if(L[u]==Y):\n",
    "                suite_impos= False\n",
    "                prev = 0\n",
    "                idx = index[u]\n",
    "                for tpl in somme :\n",
    "                    if tpl[0]<Y:\n",
    "                        prev = tpl[1]\n",
    "                e = prev + idx ##car l'index commence à 1 et non 0\n",
    "                start_string = e\n",
    "\n",
    "        char_found = False\n",
    "        for u in reversed(range(r,s+1)):\n",
    "            if(char_found or suite_impos):\n",
    "                break\n",
    "            if(L[u]==Y):\n",
    "                char_found = True\n",
    "                prev = 0\n",
    "                idx = index[u]\n",
    "                for tpl in somme :\n",
    "                    if tpl[0]<Y:\n",
    "                        prev = tpl[1]\n",
    "                f = prev + idx ##car l'index commence à 1 et non 0\n",
    "                end_string = f\n",
    "        if suite_impos :## this will stop the loop if no char has been found in the previous one\n",
    "            break\n",
    "        i -= 1\n",
    "    if suite_impos:\n",
    "        i = 0\n",
    "        pattern_in_S = False\n",
    "        return pattern_in_S,start_string,end_string\n",
    "    ##dans le cas où e = f, il faut vérifier que le reste du substring est bon\n",
    "    if i > 0 :\n",
    "        while i > 0 :\n",
    "            if L[e] != lpattern[i-1]:\n",
    "                break\n",
    "            prev = 0\n",
    "            idx = index[e]\n",
    "            start_string = e\n",
    "            end_string = e\n",
    "            for tpl in somme :\n",
    "                if tpl[0]<L[e]:\n",
    "                    prev = tpl[1]\n",
    "\n",
    "            e = prev + idx\n",
    "            i -= 1\n",
    "        idx = index[e]\n",
    "        start_string = e\n",
    "        end_string = e\n",
    "    if i < 1 :\n",
    "        pattern_in_S = True\n",
    "    return pattern_in_S,start_string,end_string\n",
    "\n",
    "def string_location(text,string,matches,suffix_table):\n",
    "    '''\n",
    "    Gives the position of each occurence of the substring in the text\n",
    "\n",
    "    Args :\n",
    "        text (string) : the text to search in\n",
    "        string (string) : the substring to be searched\n",
    "\n",
    "    Return :\n",
    "        ???\n",
    "    '''\n",
    "    result = matches\n",
    "    #print(result[1],result[2])\n",
    "    sft = suffix_table\n",
    "    list_occur = []\n",
    "    if result[0] == False :\n",
    "        #print(\"No occurence of the substring was found\")\n",
    "        list_occur.append(-1)\n",
    "    else :\n",
    "        for i in range(result[1],(result[2]+1)):\n",
    "            ##print(text[sft[i-1]-1],\"ici\")\n",
    "            idx = sft[i]\n",
    "            list_occur.append(idx)\n",
    "            #print(text[idx:idx+len(string)])\n",
    "    return(list_occur)\n",
    "\n",
    "def k_positioning(text,patt,bwt,suffix_table,index,somme):##permet d'obtenir la liste des positions\n",
    "    ##recuperation des positions des premiers et derniers patterns trouvés\n",
    "    mat = pattern_matching_BWT(text,patt,bwt,index,somme)\n",
    "    ##recupération et renvoi des positions de tout les patterns\n",
    "    return string_location(text,patt,mat,suffix_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211ad17d",
   "metadata": {},
   "source": [
    "### Fonctions d'assemblages des kmers \n",
    "\n",
    "Compexité des algorithms :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b57b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_reads(data,k):\n",
    "    \"\"\"\n",
    "    give_position of each read\n",
    "    Args:\n",
    "        data :List containing the treatment of kmer by mapping :\n",
    "        (kmer_seq, seq_name, kmer_pos, pos_genom_list)\n",
    "        kmer_seq : kmer,\n",
    "        seq_name : read containing the kmer,\n",
    "        kmer_pos : position of the kmer in the read,\n",
    "        pos_genom_list : possible positions of the kmer in the genom\n",
    "        k : length of kmers\n",
    "\n",
    "    Return:\n",
    "        ?\n",
    "    \"\"\"\n",
    "   \n",
    "    read_pos=[]##creating a list of positions according to the read name with the position in the read\n",
    "    stock_seq_name= data[0][1] #we take the first name in the list to initialize\n",
    "    pres_list = []\n",
    "    i = 0\n",
    "    temp_pres_list = []\n",
    "    for kmer_seq, seq_name, kmer_pos, pos_genom_list in tqdm(data, desc = \"Liaison des kmer de séquence n°\") :\n",
    "        if (seq_name==stock_seq_name):\n",
    "            read_pos.append(pos_genom_list)\n",
    "        else :\n",
    "            for j in range(len(pos_genom_list)) :\n",
    "                list_for_k = [read_pos[0][j], read_pos[1][j], read_pos[2][j], read_pos[3][j],\n",
    "                              read_pos[4][j], read_pos[5][j], read_pos[6][j], read_pos[7][j],\n",
    "                              read_pos[8][j], read_pos[9][j]]\n",
    "                #print(list_for_k)\n",
    "                \n",
    "                temp_pres_list.append(list(link_reads(list_for_k,k)))\n",
    "            \n",
    "            read_pos = [pos_genom_list]\n",
    "            pres_list.append([stock_seq_name, temp_pres_list])\n",
    "            stock_seq_name= data[i + 1][1]\n",
    "            temp_pres_list = []\n",
    "        i +=1\n",
    "    \n",
    "    pres_list.append([stock_seq_name, temp_pres_list])\n",
    "    \n",
    "    return pres_list\n",
    "    \n",
    "    \n",
    "def link_reads (l_pos,k):\n",
    "    \"\"\"\n",
    "    Links the kmer of the reads\n",
    "    Args:\n",
    "        l_pos : list of tuple : (kmer_pos_read, kmer_pos_gen)\n",
    "        kmer_pos_read : position of the kmer in the read\n",
    "        kmer_pos_gen : possible position of the kmer in the genom\n",
    "        k : length of kmers\n",
    "    Return:\n",
    "\n",
    "    \"\"\"\n",
    "    valid=False # true if there is a valid position\n",
    "    val_pos=[] # list of valid starting position of the read in the genom\n",
    "    comment=\"\"\n",
    "    for i in l_pos[0][1] :# for each first position,we add the next part to see if it exists\n",
    "        cur_pos=1\n",
    "        if(cur_pos==len(l_pos)): # if there is only one position in the list\n",
    "            if (i!=-1): #if there is only a position -1 it returns False and no position\n",
    "                valid=True\n",
    "                val_pos.append(i)\n",
    "\n",
    "        else :  # if there is more than 1 element iiin the list\n",
    "            pos_gen=i+k # next position of the kmer of the read in the genom\n",
    "            while (pos_gen in l_pos[cur_pos][1]) : # we try to find the next kmer in the next list of position of kmer\n",
    "                cur_pos+=1\n",
    "                if(cur_pos==len(l_pos)): # when there is the whole read in the genom\n",
    "                    valid=True\n",
    "                    val_pos.append(i)# to return the position of the read(s) in the genom\n",
    "                    break\n",
    "                else :\n",
    "                    pos_gen+=k\n",
    "    if(valid==False):\n",
    "        for i in l_pos[0][1] :# for each first position,we look at the last kmer to see if it can correpond with the genom but with mutation between\n",
    "            cur_pos=1\n",
    "            if(cur_pos!=len(l_pos)):   # if there is more than 1 element in the list\n",
    "                pos_gen=i+k*(len(l_pos)-1) #  position of the last kmer of the read in the genom\n",
    "                if (pos_gen in l_pos[-1][1]) : # we try to find the last position in the last element of the list\n",
    "                        comment+=\"possible mutation\"\n",
    "                        val_pos.append(i)# to return the position of the read(s) in the genom\n",
    "                        valid = True\n",
    "                        break\n",
    "\n",
    "    return (valid, val_pos,comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79c3e7e",
   "metadata": {},
   "source": [
    "### Fonction du fichier de sortie du programme\n",
    "\n",
    "Complexité des algorithms : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f3b7760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_result(result, list_genom) :\n",
    "    \"\"\"\n",
    "    Ecrit les résultats obtenus du mapping pour chaque read dans un fichier texte\n",
    "    \"\"\"\n",
    "    longueur_read = 100 #Ici on sait que c'est 100, changer en detection automatique si j'ai le temps\n",
    "    with open(\"result.txt\", 'w') as f: # On ouvre le fichier résultat\n",
    "            f.write(\"Name_seq\" + \"\\t\" + \"\\t\" + \"Find ?\" + \"\\t\" + \"Where : n° chromosome brin : start\" + \"\\n\") # On écrit le header\n",
    "            for i in range(len(result)) :\n",
    "                line = result[i][0]\n",
    "                find = False\n",
    "                pos = \"\"\n",
    "                for j in range(len(result[i][1])) :\n",
    "                    if result[i][1][j][0] == True :\n",
    "                        find = True\n",
    "                        for el in result[i][1][j][1] :\n",
    "                            if j+1 > 15 :\n",
    "                                if result[i][1][j][2] == \"possible mutation\" :\n",
    "                                    pos += str(j-15+1) + \" - : \" + \"~\" + str(len(list_genom[j-15][0]) - longueur_read - el + 1 ) + \"\\t\"\n",
    "                                else :\n",
    "                                    pos += str(j-15+1) + \" - : \" + str(len(list_genom[j-15][0]) - longueur_read - el + 1 ) + \"\\t\"\n",
    "                            else :\n",
    "                                if result[i][1][j][2] == \"possible mutation\" :\n",
    "                                    pos += str(j+1) + \" + : \" + \"~\" + str(el + 1) + \"\\t\"\n",
    "                                else :\n",
    "                                    pos += str(j+1) + \" + : \" + str(el + 1) + \"\\t\"\n",
    "                if find == False :\n",
    "                    line += \"\\tFalse\"\n",
    "                else :\n",
    "                    line += \"\\tTrue\" + \"\\t\" + pos\n",
    "                f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33a1f78",
   "metadata": {},
   "source": [
    "## Appels des fonctions et déroulé du programme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54057ea3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Import sequence: 1500000it [00:32, 46217.32it/s]\n",
      "Mapping sur chromosome brin sens: 100%|███████████████████████████████████████████| 15/15 [11:56:42<00:00, 2866.81s/it]\n",
      "Mapping sur chromosome brin anti-sens:  80%|█████████████████████████████▌       | 12/15 [8:42:54<2:10:43, 2614.56s/it]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2812\\266505683.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0msomme\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[0mactual_mapping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlist_reads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_positioning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_genom_inv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"$\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlist_reads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbwt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlist_genom_inv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msomme\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m     \u001b[0mfull_mapping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual_mapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[0mactual_mapping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2812\\4053961644.py\u001b[0m in \u001b[0;36mk_positioning\u001b[1;34m(text, patt, bwt, suffix_table, index, somme)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mk_positioning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpatt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbwt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msuffix_table\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msomme\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;31m##permet d'obtenir la liste des positions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;31m##recuperation des positions des premiers et derniers patterns trouvés\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m     \u001b[0mmat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpattern_matching_BWT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpatt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbwt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msomme\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;31m##recupération et renvoi des positions de tout les patterns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mstring_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpatt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msuffix_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2812\\4053961644.py\u001b[0m in \u001b[0;36mpattern_matching_BWT\u001b[1;34m(S, pattern, bwt, index, somme)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \"\"\"\n\u001b[0;32m     33\u001b[0m     \u001b[0mpattern_in_S\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbwt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0mlpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mstart_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "k = 10 # On défini k, la longueur de chaque kmers\n",
    "by_DC3 = False # True : on calcule la DC3 depuis les données, False : on la récupère depuis le fichier de sauvegarde\n",
    "\n",
    "# Variables à changer\n",
    "born_inf = 0\n",
    "born_sup = 0\n",
    "\n",
    "\n",
    "list_genom = genome_import() # On récupère la séquence du génome, chaque chromose étant compartimenté dans la liste\n",
    "\n",
    "list_reads= reads_import_cuts(k) # On récupère les reads obtenu lors du séquençage et on les découpes, chaque élément de la liste correspond à 1 kmer\n",
    "\n",
    "# On crée le brin inverse complémentaire du génome :\n",
    "list_genom_inv = []\n",
    "for data in list_genom :\n",
    "    genom = Seq(data[0])\n",
    "    genom = genom.reverse_complement()\n",
    "    list_genom_inv.append([str(genom), data[1] + \" : compl inv\"])\n",
    "\n",
    "# On calcule/importe la table des suffixes pour les génomes  \n",
    "\n",
    "if by_DC3 == True :\n",
    "    # Brin sens\n",
    "    for i in tqdm(range(len(list_genom)), desc = \"Calcul DC3\") :\n",
    "        data = DC3(list_genom[i][0] + \"$\")\n",
    "        list_genom[i].append(data)\n",
    "    # Brin anti-sens\n",
    "    for i in tqdm(range(len(list_genom_inv)), desc = \"Calcul DC3 brin complémentaire inverse\") :\n",
    "        data = DC3(list_genom_inv[i][0] + \"$\")\n",
    "        list_genom_inv[i].append(data)\n",
    "    \n",
    "else :\n",
    "    # Brin sens\n",
    "    for i in range(len(list_genom)) :\n",
    "        filename1 = \"DC3_chrom\"\n",
    "        filename3 = \".txt\"\n",
    "        filename = filename1 + str(i+1) + filename3\n",
    "\n",
    "        list_genom[i].append(import_DC3(filename))\n",
    "    # Brin anti-sens\n",
    "    for i in range(len(list_genom)) :\n",
    "        filename1 = \"DC3_chrom\"\n",
    "        filename3 = \".txt\"\n",
    "        filename = filename1 + str(i+1) + \"_inv\" + filename3\n",
    "\n",
    "        list_genom_inv[i].append(import_DC3(filename))\n",
    "\n",
    "# On effectue le mapping et on le stocke dans une liste\n",
    "\n",
    "full_mapping = [] # Liste totale de mapping qui regroupe tous les chromosomes\n",
    "actual_mapping = [] # Liste temporaire qui accueille le mapping de chaque kmer par chromosome\n",
    "\n",
    "for i in tqdm(range(len(list_genom)), desc = \"Mapping sur chromosome brin sens\") :\n",
    "    bwt = BWT(list_genom[i][0] + \"$\",list_genom[i][2])\n",
    "    ##initialisation de l'alphabet, de l'index et du compteur total de char\n",
    "    L = list(bwt)\n",
    "    alphabet = ['$','A','C','G','T']\n",
    "    index = []\n",
    "    char_index = {}\n",
    "    for char in L:\n",
    "        if char not in char_index: \n",
    "            char_index[char] = 0\n",
    "        index.append(char_index[char])\n",
    "        char_index[char] += 1\n",
    "    total = Counter(list_genom[i][0] + \"$\")\n",
    "    som = 0\n",
    "    somme = []\n",
    "    for char in alphabet:\n",
    "        som += total[char]\n",
    "        somme.append((char,som))\n",
    "    for j in range(born_inf, born_sup) :\n",
    "        actual_mapping.append([list_reads[j][2], k_positioning(list_genom[i][0] + \"$\",list_reads[j][0], bwt,list_genom[i][2],index,somme)])\n",
    "    full_mapping.append(actual_mapping)\n",
    "    actual_mapping = []\n",
    "\n",
    "# et sur le brin complémentaire :\n",
    "actual_mapping = [] # Liste temporaire qui accueille le mapping de chaque kmer par chromosome\n",
    "for i in tqdm(range(len(list_genom_inv)), desc = \"Mapping sur chromosome brin anti-sens\") :\n",
    "    bwt = BWT(list_genom_inv[i][0] + \"$\",list_genom_inv[i][2])\n",
    "    ##initialisation de l'alphabet, de l'index et du compteur total de char\n",
    "    L = list(bwt)\n",
    "    alphabet = ['$','A','C','G','T']\n",
    "    index = []\n",
    "    char_index = {}\n",
    "    for char in L:\n",
    "        if char not in char_index: \n",
    "            char_index[char] = 0\n",
    "        index.append(char_index[char])\n",
    "        char_index[char] += 1\n",
    "    total = Counter(list_genom_inv[i][0] +\"$\")\n",
    "    som = 0\n",
    "    somme = []\n",
    "    for char in alphabet:\n",
    "        som += total[char]\n",
    "        somme.append((char,som))\n",
    "    for j in range(born_inf, born_sup) :\n",
    "        actual_mapping.append([list_reads[j][2], k_positioning(list_genom_inv[i][0] + \"$\",list_reads[j][0], bwt,list_genom_inv[i][2],index,somme)])\n",
    "    full_mapping.append(actual_mapping)\n",
    "    actual_mapping = []\n",
    "\n",
    "    \n",
    "# On réorganise les données pour associer à chaque kmer sa liste de position pour tout les chromosomes et dans les deux sens\n",
    "for i in range(len(full_mapping[0])) :\n",
    "    list_reads[born_inf + i].append([full_mapping[0][i], full_mapping[1][i], full_mapping[2][i], full_mapping[3][i], full_mapping[4][i], full_mapping[5][i],\n",
    "                          full_mapping[6][i], full_mapping[7][i], full_mapping[8][i], full_mapping[9][i], full_mapping[10][i], full_mapping[11][i],\n",
    "                          full_mapping[12][i], full_mapping[13][i], full_mapping[14][i], #tout les chromosomes brin sens\n",
    "                          full_mapping[15][i], full_mapping[16][i], full_mapping[17][i], full_mapping[18][i], full_mapping[19][i], full_mapping[20][i],\n",
    "                          full_mapping[21][i], full_mapping[22][i], full_mapping[23][i], full_mapping[24][i], full_mapping[25][i], full_mapping[26][i],\n",
    "                          full_mapping[27][i], full_mapping[28][i], full_mapping[29][i]]) #tout les chromosomes brin anti-sens\n",
    "\n",
    "# On teste la possibilité de présence de la séquenbce :\n",
    "result = prepare_reads(list_reads[born_inf:born_sup], k)\n",
    "\n",
    "export_result(result, list_genom)\n",
    "\n",
    "time_imp = datetime.now() - now\n",
    "print(\"Travail effectué en\", time_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7208fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4cf880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cprofile !\n",
    "\n",
    "# -10h30 au total pour temps réel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
