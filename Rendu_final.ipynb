{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4fb17e1",
   "metadata": {},
   "source": [
    "## Partie Analyse des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f36785",
   "metadata": {},
   "source": [
    "#### Présentation du programme\n",
    "Le projet à réaliser consiste à réaliser le positionnement de sous-séquences, appellées \"reads\", sur un génome. Afin de gagner en précision et de pallier aux mutations engendrées par le séquençage des reads, le paramètre k permet de choisir la taille de découpage de la séquence. Pour gagner en efficacité, le programme se base sur l'algorithme DC3 et sur la Burrows Wheeler Transform. Enfin les reads sont reconstruits selon 2 méthodes, la premières identifiera les positions susceptibles de présenter le read en se basant sur le premier et dernier morceau, ensuite ceux-ci seront analysés afin de trouver les positions exactes des sous-séquences. Si aucune position exacte n'est trouvé, il y a du alors y avoir mutation et le fichier sortira la position avec un ~ devant le nombre.\n",
    "\n",
    "#### Fichiers de sortie et temps estimé\n",
    "Les résultats de l'algorithme se retrouvent après lancement dans le fichier result.txt. Nous avons regroupé les résultats obtenus sur les reads du premier chromosome dans le fichier result_all.txt. Ce fichier ne regroupe pas tous les résultats des algorithmes, car nous avons lancé sur plusieurs machines afin de pallier au temps estimé d'exécution du programme, (qui est de 75 jours pour un k = 10 !) mais n'avons obtenu qu'un seul chromosome complet.(Au vu des résultats des morceaux obtenus, le résultat prédit par tqdm est assez robuste même si le temps peut varier très fortement entre les différents reads, on se retrouve en moyennes sur le temps prédit après stabilistaion sur quelques reads courts). En augmentant k à 50, on divise le temps de calcul par 5, certes, mais on perd en précision comme le montrera l'analyse des données.\n",
    "\n",
    "L'algorithme est cependant assez gourmand en mémoire, afin de lancer l'algorithme avec le calcul de DC3 sans passer par l'import de données depuis le fichier texte il est conseillé de pouvoir allouer plus de 10G de RAM au notebook. Sinon la version import permet d'outre-passer cette barrière (un PC \"classique\" à 8G pourra le faire tourner sans problème).\n",
    "\n",
    "#### Disclaimer à propos des données :\n",
    "Ce processus a necessité de recoder notre algorithme pour le faire fonctionner en \"mode partition\", ce qui a induit certaines erreurs de classification dans la sortie des premiers reads lancés, ainsi pour résumer : Les 10000 premiers (de NC_004325.2-100000 à NC_004325.2-90000) ont été recalculé et sont donc correct, cependant la tranche 10000-40000 et 60000-70000 contient des erreurs des classifications (certaines positions n'ont pas la ~ correspondant à une mutation à tort !) et certaines positions vers 200000 également. Cependant en laçant le programme actuellement, ce soucis ne se produira pas. Ces séquences seront écartées pour le choix de l'échantillon car elles ne permettent pas une distinction assez précise pour la quailté mais reste un bon indicateur de précision du mapping et seront comptés ainsi.\n",
    "\n",
    "#### Etude des données\n",
    "Comme il y a beaucoup de données, les vérifications de la validité de l'algorithme se feront sur l'échantillon 0-10000 et on tirera aléatoirement 200 résultats à analyser pour généraliser à l'ensemble du jeu de données. Nous avons pris le choix d'étendre l'échantillon à 250 afin de voir le gain en précision bien que la p-value soit déja assez significatif pour l'hypothèse de représentaivité des données. (Voir fichier Stat_R.jpeg) \n",
    "\n",
    "L'étude à ensuite été élargie sur tous les autres intervalles obtenus du génome et, en sélectionnant 10 reads par chromosome, a constitué un nouvel échantillon pour tester l'efficacité globale de l'algorithme.\n",
    "\n",
    "Les annotations réalisées et les divers comptages et pourcentages ont été recensés dans les fichiers présents dans le dossier \"Interpretation manuelle\" du dossier \"result_save\".\n",
    "\n",
    "#### Interprétations des résultats\n",
    "Tout d'abord, le choix de k est un paramètre très important nous l'avons fixé à 10 (choisi avant la comparaison mais on connaissait déja l'influence qu'aurait ce paramètre) car il permet d'obtenir des résultats plus significatif en diminuant sa valeur (47% de positions mappés pour k = 50 contre 69% pour k = 25 et 87% pour k = 10). Ainsi bien qu'encore très long à calculer cela nous aura permis d'analyser des résultats de plutôt bonne qualité.\n",
    "\n",
    "Les résultats obtenus sur le premier chromosome nous montrent qu'en comparaison avec le fichier BAM distribué, on retrouve près de 80% de positions prédites identiques. Dans les 20% restant se trouvent les positions qui n'ont pas été mappées (~13%), quelques positions qui prédisent la bonne position, mais avec d'autres positions qui ont le même degré de certitude donc que notre algorithme ne saura pas trier/mettre en avant, et une position qui diffèrent du fichier BAM. Cette dernière s'explique à la façon dont à été codé notre algorithme : on regarde la première et la dernière position, or dans le cas du fichier BAM, les extrémités de la séquence prédite n'étaient pas totalement couverte (moins de 10 nucléotides en amont et aval) mais contenait une excellente couverture du read sur le milieu (60 qui s'enchainaient).\n",
    "\n",
    "Concernant l'extrapolation à l'ensemble des données, on observe que globalement on observe que le pourcentage de correctement mappées diminuent légérement au profit des mal mappées et des incertaines. Mais impossible de tirer de vraies conclusions sachant que le premier échantillon étant plus gros n'avait pas réussi à être représentatif.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4468d29f",
   "metadata": {},
   "source": [
    "## Partie Code :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cda49f",
   "metadata": {},
   "source": [
    "### Définition des paramètres :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae2b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10 # On défini k, la longueur de chaque kmers\n",
    "by_DC3 = False # True : on calcule la DC3 depuis les données, False : on la récupère depuis le fichier de sauvegarde\n",
    "start = 0 # On commence par le premier read sinon modifier ligne 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e12a90",
   "metadata": {},
   "source": [
    "### Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81d25d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies nécessaire à l'exécution du programme\n",
    "from Bio import SeqIO # Permet l'import de la fonction parse du module pour lire les fichiers fasta/fastq\n",
    "from Bio.Seq import Seq # Permet la transformation en complémentaire inverse de séquences\n",
    "from Bio.SeqIO.QualityIO import FastqGeneralIterator # Permet un parse plus rapide lorsque beaucoup de séquences (fastaq uniquement sinon voir site biopython pour fasta)\n",
    "import functools as ft # Permet de regrouper des listes pour radix sort\n",
    "from collections import Counter # Permet de compter les occurences d'un charactère dans un texte de manière efficace\n",
    "import numpy as np # DC3 utilise un tableau numpy pour stocker ses données\n",
    "\n",
    "# Librairies optionelles à l'éxécution du programme\n",
    "from tqdm import tqdm # Permet d'estimer le temps d'éxécution sur un boucle\n",
    "from datetime import datetime # Permet de comparer la vitesse de 2 programmes \n",
    "#%load_ext snakeviz # Permet d'optimiser le temps d'execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d402b8",
   "metadata": {},
   "source": [
    "### Fonctions d'import des données :\n",
    "\n",
    "Complexité des algorithms : \n",
    "\n",
    "Tous : linéaire en temps avec le nombre d'éléments à importer (ou nombre d'élément fois taille du read/k pour import_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee27be11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_DC3(filename) :\n",
    "    \"\"\"\n",
    "    Fonction qui importe depuis un fichier texte la table des suffixes du génome par DC3 et la stocke dans une liste\n",
    "    \"\"\"\n",
    "    filename = \"DC3_save/\" + filename\n",
    "    with open(filename, 'r') as f: # On ouvre le fichier et on fait la procédure inverse au stockage\n",
    "        text = f.readline()\n",
    "        data = text.split(\" \")[:-1]\n",
    "        for i in range(len(data)) :\n",
    "            data[i] = int(data[i])\n",
    "        return(data)\n",
    "    # La fonction d'export de DC3 peut nottament être retrouve dans Association_codes.ipynb\n",
    "    \n",
    "def genome_import() :\n",
    "    \"\"\"\n",
    "    Fonction qui importe depuis un fichier fasta la séquence du génome dans une liste contenant [\"seq\", \"n°k\"]\n",
    "    \"\"\"\n",
    "    list_genom=[]\n",
    "    for record in SeqIO.parse(\"GCF_000002765.5_GCA_000002765_genomic.fna\",\"fasta\"):\n",
    "        list_genom.append([str(record.seq).upper(),record.description[-14:]]) # attention le marquage est à changer pour la dernière séquence\n",
    "    \n",
    "    return list_genom\n",
    "    \n",
    "def reads_import_cuts(k) :\n",
    "    \"\"\"\n",
    "    Fonction qui importe depuis un fichier fasta les séquences des reads et les coupes en les rangeant\n",
    "    dans une liste contenant [\"seq\", \"nom\", \"n°kmer\"]\n",
    "    \n",
    "    Entrée : k, int : longueur du kmer\n",
    "    \n",
    "    Sortie : list_reads : liste de tous les read découpés en kmers\n",
    "    \"\"\"\n",
    "    list_reads=[]\n",
    "    with open(\"single_Pfal_dat.fq\") as in_handle:\n",
    "        for title, seq, qual in tqdm(FastqGeneralIterator(in_handle), desc = \"Initialisation - Import sequence\"):\n",
    "            i = 1    # Incrémenteur du nombre de k-mer\n",
    "            while len(seq) >= 1 : # On parcoure toute la séquence\n",
    "                if len(seq) > k : # Cas où le k-mer est entier\n",
    "                    list_reads.append([str(seq[0:k]).upper(),title, i])\n",
    "                    i += 1\n",
    "                    seq = seq[k:]\n",
    "                else : # Cas où le dernier k-mer n'est pas entier\n",
    "                    list_reads.append([str(seq).upper(),title, i])\n",
    "                    seq = \"\"\n",
    "                    i += 1 # Pour avoir le bon nombre de kmer s'il en reste un dernier\n",
    "            \n",
    "    return list_reads, i-1 # i-1 car on incrémente après avoir annoté"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99e14e4",
   "metadata": {},
   "source": [
    "### Fonction pour la table des suffixes (DC3)\n",
    "\n",
    "Complexité des algorithms : linéaire avec la longueur de la séquence pour DC3 et avec la taille de la liste pour les autres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd68c649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(arr):\n",
    "    \"\"\"\n",
    "    Permet de \"compresser\" une liste 2D en liste 1D (toutes les sous listes à la suite)\n",
    "    \"\"\"\n",
    "    return ft.reduce(lambda x, y: x + y, arr)\n",
    "\n",
    "def counting_sort(array,digit,p): \n",
    "    \"\"\"\n",
    "    Le counting sort est un tri stable utilisé par le tri radix\n",
    "    Ici la fonction est adaptée au format de données (triplets de nombres à plusieurs digits)\n",
    "    \n",
    "    Entrée :\n",
    "        array (list) : array à trier\n",
    "        digit (int) : digit à regarder (unités, dizaines...)\n",
    "        p (int) : numero de l'élement des triplets a regarder\n",
    "    \n",
    "    Sortie :\n",
    "        array rangé selon le digit et la position p donnée\n",
    "    \"\"\"\n",
    "    ##The counting sort is a stable sort used in the radic sort\n",
    "    ##here the counting sort needs to be adapted to look at only one digit of each number (for radix)\n",
    "    ##we also added the parameter p to be able to read the triplets (more info below)\n",
    "    ##1) since we only sort single digits, the max will always be smaller than 10\n",
    "    ##2) create count index (that will have the cumulative index in the end)\n",
    "    count_list = [[]for i in range(10)]\n",
    "    for tpl in array :\n",
    "        n_uplet = tpl[0]##we take the first element of the tuple, the n-uplet\n",
    "        num = n_uplet[p] // digit ##we cut off the digits to the right by getting the quotient of the euclidian division\n",
    "        ##p is the index of the number studied in the triplet\n",
    "        count_list[num%10].append(tpl)##we cut off the digits to the left by getting the remainder of the euclidian division\n",
    "    arr_ord = flatten(count_list)\n",
    "\n",
    "    for i in range(len(array)):##we change the base array to allow the radix sort to loop easily\n",
    "        array[i] = arr_ord[i]\n",
    "        \n",
    "def radix_sort(array,p):\n",
    "    \"\"\"\n",
    "    Prend en entrée un tableau de valeur de valeur et le trie en foncion de la première composante\n",
    "    selon l'algorithm du radix sort\n",
    "    \n",
    "    Entrée : array à trier\n",
    "             p : nombre de cases à trier p-uplets\n",
    "    \n",
    "    Sortie : array trié\n",
    "    \"\"\"\n",
    "    ##Here the radix sort is modified to work with the triplet list sent by the DC3\n",
    "    ##The code is not flexible enough to compute all characters in the ascii table, but it's enough for the use needed\n",
    "    ##1) we search for the max in the nuplets\n",
    "    mx = (max(array)[0])[0]+1\n",
    "    if p != 3 : ##we take max = 100 because A T C G are all below 100 in ascii code\n",
    "        for tpl in array:\n",
    "            n_uplet = tpl[0]\n",
    "            if n_uplet[-1] > mx :\n",
    "                mx = n_uplet[-1]+1\n",
    "    '''##2) to know how many loops we have to do, we will use a variable to represent,\n",
    "    the digit we are currently in'''\n",
    "    for i in reversed(range(0,p)):\n",
    "        digit = 1 ##starts at one for units\n",
    "        while mx - digit > 0 :##when all the digits are checked, digit will be greater than the maximum\n",
    "            counting_sort(array,digit,i)\n",
    "            digit *= 10 ##digit will go to the tens, the hundreds, the thousands...\n",
    "            \n",
    "def DC3(S, P_12_base = []) : # On initialise P_12_base comme étant vide car elle n'est pas utilisé pour la première récursion\n",
    "    \"\"\"\n",
    "    Create the suffix array from DC3 algorithm, could be recursive if needed\n",
    "    \n",
    "    Args:\n",
    "        S (str): string\n",
    "        P_12_base : store P1+2 from recursion to map correctly recursivity\n",
    "    \n",
    "    Return:\n",
    "        index_012 : suffix array of S\n",
    "        order_12 : order of the next recursion to map correctly recursivity\n",
    "    \"\"\"\n",
    "    DC3_table = np.zeros((3,len(S) + 3), dtype=int) # Les caractères sentinelles sont déja là !\n",
    "    \"\"\"\n",
    "    Table de DC3 qui contient en chaque ligne : \n",
    "    Ligne 0 : indice du caractère, optionelle en soit mais permet un debugging plus efficace\n",
    "    Ligne 1 : conversion du caractère en nombre\n",
    "    Ligne 2 : Ordre de l'indice du caractère\n",
    "    \n",
    "    \"\"\"\n",
    "    for i in range(len(S) + 3) :\n",
    "            DC3_table[0][i] =  i  # On initialise les indices\n",
    "    \n",
    "    # String conversion : !!!!! à n'executer que lors de la première récursion !!!!!\n",
    "    if type(S) == str :\n",
    "        S_l = [*S] # On sépare caractère par caractère : \"ATGC\" devient [\"A\",\"T\",\"G\",\"C\"]\n",
    "        for i in range(len(S_l)) :\n",
    "            DC3_table[1][i] =  ord(S_l[i]) # On rempli le caractère par son code Ascii dans la table\n",
    "    else :\n",
    "         for i in range(len(S)) :\n",
    "            DC3_table[1][i] =  S[i] # Cas où l'on rentre dans la boucle une deuxième fois ou plus, pas de conversion\n",
    "            \n",
    "    # On crée P0, P1, P2 et P1+P2 :    \n",
    "    P0 = [*range(0,len(S)+1,3)] \n",
    "    P1 = [*range(1,len(S)+1,3)]\n",
    "    P2 = [*range(2,len(S)+1,3)]\n",
    "    P_12 = P1 + P2\n",
    "    \n",
    "    #Obtention des triplets à partir de P1+P2 :\n",
    "    R_12 = []\n",
    "    for val in P_12 :\n",
    "        R_12.append([list(DC3_table[1][val:val+3]), val])\n",
    "    \n",
    "    radix_sort(R_12,3) # On trie les triplets\n",
    "\n",
    "    index_12 = [] # Liste des indexes de R12 trié\n",
    "    order_count = 1 # Compteur pour remplir l'ordre\n",
    "    recur = False # Etat de la récursion, tourné True si on a des égalités d'ordre\n",
    "    for j in range(len(R_12)) : # On parcours tous les triplets triés\n",
    "        index_12.append(R_12[j][1]) # ... pour lui attribuer son index depuis P_12\n",
    "        DC3_table[2][R_12[j][1]] = order_count # Et on ajoute l'ordre dans la table\n",
    "        if j < len(R_12)-1 : # On compare à celui d'après \n",
    "            if R_12[j][0] != R_12[j+1][0] : # On teste l'égalité des triplets pour mettre l'ordre\n",
    "                order_count += 1\n",
    "            else :\n",
    "                recur = True # On a égalité, donc on doit relancer l'algorithme à la fin du for\n",
    "        else :\n",
    "            order_count += 1 # Le dernier est forcément d'ordre différent sinon on le voit sur celui d'avant\n",
    "\n",
    "    if recur == True :\n",
    "        new_S = [] # On crée T' la séquence des orders suivant l'ordre de P12\n",
    "        for l in P_12 :\n",
    "            new_S.append(DC3_table[2][l]) # On prend les ordres des indices de P1+2\n",
    "        index_012 = DC3(new_S, P_12) # On doit donner ces deux paramètres sinon lorsqu'on revient dans le programme on a pas les bons indexes\n",
    "        index_12 = []\n",
    "        for ind,val in index_012 :\n",
    "            DC3_table[2][ind] = val # On met à jour les ordres ...\n",
    "            index_12.append(ind) # ... et on récupère les indices\n",
    "    \n",
    "    R_0 = [] # On crée la dernière partie à trier\n",
    "    for val in P0 :\n",
    "        R_0.append([[int(DC3_table[1][val]), DC3_table[2][val + 1]], val]) # On crée R0 avec son indice\n",
    "    \n",
    "    \n",
    "    radix_sort(R_0,2) # On trie à nouveau mais des doublets cette fois\n",
    "    \n",
    "    index_0 = [] # Liste des indexes de R0 trié\n",
    "    for k in range(len(R_0)) : # On parcours tous les doublets triés\n",
    "       index_0.append(R_0[k][1]) # On récupère l'indice\n",
    "    \n",
    "    index_012 = [] # On crée l'index final en ordonant 0 et 1,2\n",
    "    i_0 = 0 # On initialise les compteurs de chaque listes (index_0 et index_12)\n",
    "    i_12 = 0\n",
    "    \n",
    "    index_12_dict = {} # On crée un dictionnaire des index et de leurs indice dans la liste pour accélèrer le processus de tri\n",
    "    for i in range(len(index_12)) :\n",
    "        index_12_dict[index_12[i]] = i\n",
    "    # On commence le tri des listes\n",
    "    while (i_0 < len(index_0) and i_12 < len(index_12)) : # On prends tout les éléments : on vide index 0 ou 12\n",
    "        val_i0 = index_0[i_0]\n",
    "        val_i12 = index_12[i_12]\n",
    "        if DC3_table[1][val_i0] > DC3_table[1][val_i12] : # Cas où index 12 arrive avant index 0\n",
    "            index_012.append(index_12[i_12])\n",
    "            i_12 += 1\n",
    "        elif DC3_table[1][val_i0] < DC3_table[1][val_i12] : # Cas où index 0 arrive avant index 12\n",
    "            index_012.append(index_0[i_0])\n",
    "            i_0 += 1\n",
    "        else : # Cas d'égalité sur l'indice : si les 2 indexes renvoient le même nombre \n",
    "            if index_12[i_12] % 3 == 1 :\n",
    "                if index_12_dict[val_i0 + 1] > index_12_dict[val_i12 + 1] : # Cas où index 12 au deuxième terme arrive avant index 0 au deuxième terme\n",
    "                    index_012.append(index_12[i_12])\n",
    "                    i_12 += 1\n",
    "                else : # Cas où index 0 au deuxième terme arrive avant index 12 au deuxième terme\n",
    "                    index_012.append(index_0[i_0])\n",
    "                    i_0 += 1\n",
    "            else :\n",
    "                if DC3_table[1][val_i0 + 1] > DC3_table[1][val_i12 + 1] : # On teste dabord cas où index 12 + 1 arrive avant index 0 + 1\n",
    "                    index_012.append(index_12[i_12])\n",
    "                    i_12 += 1\n",
    "                elif DC3_table[1][val_i0 + 1] < DC3_table[1][val_i12 + 1] : # Cas où index 0 + 1 arrive avant index 12 + 1\n",
    "                    index_012.append(index_0[i_0])\n",
    "                    i_0 += 1\n",
    "                elif index_12_dict[val_i0 + 2] > index_12_dict[val_i12 + 2] : # Cas où index 12 au deuxième terme arrive avant index 0 au troisième terme\n",
    "                    index_012.append(index_12[i_12])\n",
    "                    i_12 += 1\n",
    "                else : # Cas où index 0 au troisième terme arrive avant index 12 au deuxième terme\n",
    "                    index_012.append(index_0[i_0])\n",
    "                    i_0 += 1\n",
    "    \n",
    "    index_012.extend(index_12[i_12:]) # Si 1 des deux index est encore plein, on ajoute son contenu\n",
    "    index_012.extend(index_0[i_0:])\n",
    "\n",
    "    if int(DC3_table[1][index_012[0]]) == 0 : # On enlève le terme sentinel s'il est présent\n",
    "        index_012 = index_012[1:]\n",
    "\n",
    "    if len(P_12_base) > 0 : # Mapping sur recursion -1 si existe\n",
    "        new_index_012 = []\n",
    "        for n in range(len(index_012)) :\n",
    "            new_index_012.append([P_12_base[index_012[n]], n]) # On transfère la valeur de base et son index pour la récursion -1\n",
    "        index_012 = new_index_012\n",
    "   \n",
    "\n",
    "    return index_012 # Retourne le suffix array si dernière récursion, sinon la liste [val , index] à la récursion -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51519cc",
   "metadata": {},
   "source": [
    "### Fonctions de mapping :\n",
    "\n",
    "Complexité des algorithmes :<br>\n",
    "BWT : linéaire avec la taille du génome <br>\n",
    "pattern_matching_bwt : Dans le pire des cas, taille du génome * taille du pattern (mais ce cas est très rare)<br>\n",
    "string_location : Dans le pire des cas, taille du génome / taille du pattern (si le génome ne contient que le pattern répété)<br>\n",
    "k_positioning : O(1) (la fonction sers juste à appeler les autres), donc la complexité dépend uniquement de la fonction avec la fonction la plus grande ce qui donne taille du génome * taille du pattern dans le pire des cas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8919d6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BWT(text,suffix_table):\n",
    "    \"\"\"\n",
    "    Compute the BWT from the suffix table\n",
    "\n",
    "    Args:\n",
    "        T (str): string\n",
    "        end_of_string (char): end of string character to append\n",
    "\n",
    "    Return:\n",
    "        bwt (str): BWT\n",
    "    \"\"\"\n",
    "    bwt = \"\"\n",
    "    sf_tab = suffix_table\n",
    "    for i in range(len(sf_tab)):\n",
    "        crt = sf_tab[i]\n",
    "        bwt += text[crt-1]\n",
    "    return(bwt)\n",
    "\n",
    "def pattern_matching_BWT(S,pattern,bwt,index,somme):\n",
    "    \"\"\"\n",
    "    Search a pattern in a String using the BWT\n",
    "\n",
    "    Args:\n",
    "        S (str): string\n",
    "        pattern (str): pattern\n",
    "        bwt (str) : the bwt of the text (to not compute it each time)\n",
    "        index (list): the index for the chars in the bwt\n",
    "        somme (list): the sum of each char in the bwt\n",
    "\n",
    "    Return:\n",
    "        bool: true if the pattern is in the string\n",
    "        int : position of the first occurence of the pattern in the ordered text\n",
    "        int : position of the last occurence of the pattern in the ordered text\n",
    "    \"\"\"\n",
    "    pattern_in_S = False\n",
    "    L = list(bwt)\n",
    "    lpattern = list(pattern)\n",
    "    start_string = -1\n",
    "    end_string = -1\n",
    "    ##init des valeurs utiles pour la substring search\n",
    "    e = 0\n",
    "    f = len(L)\n",
    "    i = len(lpattern)-1\n",
    "    X = lpattern[i]##correspond au dernier char du kmer, le premier a être cherché dans la string search\n",
    "    for tpl in somme :\n",
    "        if tpl[0]<X:\n",
    "            e = tpl[1]+1 ##donne place du premier char dans la liste ordonnée\n",
    "        if tpl[0]==X:\n",
    "            f = tpl[1]-1 ##donne place du dernier char\n",
    "\n",
    "    while e < f and i > 0 :\n",
    "        X = lpattern[i]\n",
    "        Y = lpattern[i-1]\n",
    "        suite_impos = True\n",
    "        r = e\n",
    "        s = f\n",
    "        for u in range(r,s+1):##On cherche le char suivant du pattern dans la bwt\n",
    "            if(suite_impos==False):##we use the boolean to exit the loop early\n",
    "                break\n",
    "            if(L[u]==Y):\n",
    "                suite_impos= False\n",
    "                prev = 0\n",
    "                idx = index[u]\n",
    "                for tpl in somme :\n",
    "                    if tpl[0]<Y:\n",
    "                        prev = tpl[1]\n",
    "                e = prev + idx ##on calcule la position du char trouvé dans la liste des chars sorted.\n",
    "                start_string = e\n",
    "\n",
    "        char_found = False\n",
    "        for u in reversed(range(r,s+1)):\n",
    "            if(char_found or suite_impos):\n",
    "                break\n",
    "            if(L[u]==Y):\n",
    "                char_found = True\n",
    "                prev = 0\n",
    "                idx = index[u]\n",
    "                for tpl in somme :\n",
    "                    if tpl[0]<Y:\n",
    "                        prev = tpl[1]\n",
    "                f = prev + idx\n",
    "                end_string = f\n",
    "        if suite_impos :## this will stop the loop if no char has been found in the previous one\n",
    "            break\n",
    "        i -= 1\n",
    "    if suite_impos:\n",
    "        i = 0\n",
    "        pattern_in_S = False\n",
    "        return pattern_in_S,start_string,end_string\n",
    "    ##dans le cas où e = f, il faut vérifier que le reste du substring est bon\n",
    "    if i > 0 :\n",
    "        while i > 0 :##on fait une bwt inverse \"classique\" en vérifiant a chaque fois que le char suivant \n",
    "                     ##est bien le même que celui du pattern\n",
    "            if L[e] != lpattern[i-1]:\n",
    "                break\n",
    "            prev = 0\n",
    "            idx = index[e]\n",
    "            start_string = e\n",
    "            end_string = e\n",
    "            for tpl in somme :\n",
    "                if tpl[0]<L[e]:\n",
    "                    prev = tpl[1]\n",
    "\n",
    "            e = prev + idx\n",
    "            i -= 1\n",
    "        idx = index[e]\n",
    "        start_string = e\n",
    "        end_string = e\n",
    "    if i < 1 :\n",
    "        pattern_in_S = True\n",
    "    return pattern_in_S,start_string,end_string\n",
    "\n",
    "def string_location(text,string,matches,suffix_table):\n",
    "    '''\n",
    "    Gives the position of each occurence of the substring in the text\n",
    "\n",
    "    Args :\n",
    "        text (string) : the text to search in\n",
    "        string (string) : the substring that was search (the pattern)\n",
    "        matches (tuple) : the output of the pattern matching function, containing a boolean \n",
    "            to say if an occurence was found (matches[0]), the position of the first occurence \n",
    "            in the suffix table (matches[1]) and the position of the last occurence (matches[2])\n",
    "        suffix_table (list) : the ordered list of all suffixes\n",
    "\n",
    "    Return :\n",
    "        (list) : the list of all positions of the occurences of the pattern in the original text\n",
    "    '''\n",
    "    sft = suffix_table\n",
    "    list_occur = []\n",
    "    if matches[0] == False :\n",
    "        #print(\"No occurence of the substring was found\")\n",
    "        list_occur.append(-1)\n",
    "    else :\n",
    "        for i in range(matches[1],(matches[2]+1)):##les occurences du patterns se suivent toutes dans la table des suffixes\n",
    "            idx = sft[i]\n",
    "            list_occur.append(idx)\n",
    "            ##print(text[idx:idx+len(string)])\n",
    "    return(list_occur)\n",
    "\n",
    "def k_positioning(text,patt,bwt,suffix_table,index,somme):##permet d'obtenir la liste des positions\n",
    "    '''\n",
    "    Args :\n",
    "        text (string) : the text to search in\n",
    "        string (string) : the substring that will be searched (the pattern)\n",
    "        bwt (str) : the bwt of the text (to not compute it each time)\n",
    "        suffix_table (list) : the ordered list of all suffixes\n",
    "        index (list): the index for the chars in the bwt\n",
    "        somme (list): the sum of each char in the bwt\n",
    "    \n",
    "    Return :\n",
    "        (list) : the list of all positions of the occurences of the pattern in the original text\n",
    "    '''\n",
    "    ##recuperation des positions des premiers et derniers patterns trouvés\n",
    "    mat = pattern_matching_BWT(text,patt,bwt,index,somme)\n",
    "    ##recupération et renvoi des positions de tout les patterns\n",
    "    return string_location(text,patt,mat,suffix_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211ad17d",
   "metadata": {},
   "source": [
    "### Fonctions d'assemblages des kmers \n",
    "\n",
    "Compexité des algorithms : La fonction link_reads a une complexité maximale de la taille du génome, il est cependant quasiment impossible d'avoir une telle complexité puisque cela voudrait dire que le read est répété sur tout le génome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b57b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_reads(data,k, num):\n",
    "    \"\"\"\n",
    "    give_position of each read\n",
    "    Args:\n",
    "        data :List containing the treatment of kmer by mapping :\n",
    "        (seq_name, kmer_pos, pos_genom_list)\n",
    "        seq_name : read containing the kmer,\n",
    "        kmer_pos : position of the kmer in the read,\n",
    "        pos_genom_list : possible positions of the kmer in the genom\n",
    "        k : length of kmers\n",
    "        num : number of kmer\n",
    "\n",
    "    Return:\n",
    "        [data[0][0], pres_list] : List that contain sequence name, first, and his linking result, in second\n",
    "    \"\"\"\n",
    "    # Creating a list of positions that regroup for the sequence the right psotions by chromosome\n",
    "    read_pos=[[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]] \n",
    "    pres_list = [] \n",
    "    # We go through all chromosome ... (maybe need an investigation here too)\n",
    "    # ... for each chromosome because of putting them together in the same place doesn't seams to work\n",
    "     \n",
    "    for j in range(len(data[0][2])) :\n",
    "        for kmer in range(num) :\n",
    "            read_pos[j].append(data[kmer][2][j])\n",
    "    \n",
    "    for chro in range(len(data[0][2])) :\n",
    "        pres_list.append(list(link_reads(read_pos[chro],k))) # We stock the linking of the chromosome\n",
    "    \n",
    "    return [data[0][0], pres_list]\n",
    "    \n",
    "    \n",
    "def link_reads (l_pos,k):\n",
    "    \"\"\"\n",
    "    Links the kmer of the reads\n",
    "    Args:\n",
    "        l_pos : list of tuple : (kmer_pos_read, kmer_pos_gen)\n",
    "        k : length of kmers\n",
    "    Return:\n",
    "        valid : boolean of if sequence has been mapped\n",
    "        val_pos(_m) : position possible of occurence of the read\n",
    "        comment : type of the linking, if \"\"(empty) perfect linking\n",
    "\n",
    "    \"\"\"\n",
    "    valid=False # true if there is a valid position\n",
    "    val_pos=[] # list of valid starting position of the read in the genom\n",
    "    val_pos_m=[] # list of valid starting position of the mutated reads in the genom or of reads of one kmer\n",
    "    comment=\"\"\n",
    "    full=False #is true if there is the whole read at a position\n",
    "\n",
    "    for i in l_pos[0][1] :# for each first position,we look at the last kmer to see if it can correpond with the genom but with mutation between\n",
    "        if(len(l_pos)!=1):   # if there is more than 1 element in the list\n",
    "            pos_gen=i+k*(len(l_pos)-1) #  position of the last kmer of the read in the genom\n",
    "            if (pos_gen in l_pos[-1][1]) : # we try to find the last position in the last element of the list\n",
    "                    comment=\"possible mutation\"\n",
    "                    val_pos_m.append(i)# to return the position of the read(s) in the genom\n",
    "                    valid=True\n",
    "        elif(len(l_pos)==1):\n",
    "            if (i!=-1):#if there is only a position -1 it returns False and no position\n",
    "                valid=True\n",
    "                val_pos_m.append(i)\n",
    "    if(valid==True):\n",
    "        for i in val_pos_m :# for each first position find in previous,we add the next part to see if it exists\n",
    "            cur_pos=1\n",
    "            if(cur_pos!=len(l_pos)):  # if there is more than 1 element in the list\n",
    "                pos_gen=i+k # next position of the kmer of the read in the genom\n",
    "                while (pos_gen in l_pos[cur_pos][1]) : # we try to find the next kmer in the next list of position of kmer\n",
    "                    cur_pos+=1\n",
    "                    if(cur_pos==len(l_pos)): # when there is the whole read in the genom\n",
    "                        val_pos.append(i)# to return the position of the read(s) in the genom\n",
    "                        comment=\"\"\n",
    "                        full=True\n",
    "                        break\n",
    "                    else :\n",
    "                        pos_gen+=k\n",
    "\n",
    "\n",
    "    if(full):\n",
    "        return (valid, val_pos,comment)\n",
    "    else :\n",
    "        return (valid, val_pos_m,comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79c3e7e",
   "metadata": {},
   "source": [
    "### Fonction du fichier de sortie du programme\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f3b7760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_result(result) :\n",
    "    \"\"\"\n",
    "    Ecrit les résultats obtenus du mapping pour chaque read dans un fichier texte\n",
    "    \"\"\"\n",
    "    longueur_read = 100 # Ici on sait que c'est 100, changer en detection automatique si j'ai le temps\n",
    "    with open(\"result.txt\", 'a') as f: # On ouvre le fichier résultat\n",
    "            line = result[0]\n",
    "            find = False\n",
    "            pos = \"\"\n",
    "            for j in range(len(result[1])) : # Si plusieurs séquences, mais obsolète depuis la version better\n",
    "                if result[1][j][0] == True :\n",
    "                    find = True\n",
    "                    for el in result[1][j][1] :\n",
    "                        \"\"\"\n",
    "                        Ok, là on peut se dire c'est bizarre mais pour comprendre :\n",
    "                        Les chromosomes sont regroupés ensemble dans la liste donc j % 2 == 1 permet de séparer le brin sens et anti-sens\n",
    "                        Et on doit retrouver le numéro du chromose dans cette liste bizarre don on divise par 2 car on a 2 brins par chromosome\n",
    "                        Dans le brin anit-sens, le mapping doit se faire par rpport au brin sens pour garder une cohérence avec la méthode à comparer\n",
    "                        donc on retranche au total la position et la longeur du read pour avoir sa position dans le brin sens (mais qui sera inversé ducoup !)\n",
    "                        \"\"\"\n",
    "                        if j % 2 == 1 :\n",
    "                            if result[1][j][2] == \"possible mutation\" :\n",
    "                                pos += str(int(j/2) + 1) + \" - : \" + \"~\" + str(len(list_genom[int(j/2)][0]) - longueur_read - el + 1 ) + \"\\t\"\n",
    "                            else :\n",
    "                                pos += str(int(j/2) + 1) + \" - : \" + str(len(list_genom[int(j/2)][0]) - longueur_read - el + 1 ) + \"\\t\"\n",
    "                        else :\n",
    "                            if result[1][j][2] == \"possible mutation\" :\n",
    "                                pos += str(int(j/2) + 1) + \" + : \" + \"~\" + str(el + 1) + \"\\t\"\n",
    "                            else :\n",
    "                                pos += str(int(j/2) + 1) + \" + : \" + str(el + 1) + \"\\t\"\n",
    "            if find == False : # On rempli la ligne avec l'info que la séquence n'est pas mappé\n",
    "                line += \"\\tFalse\"\n",
    "            else :\n",
    "                line += \"\\tTrue\" + \"\\t\" + pos\n",
    "            f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33a1f78",
   "metadata": {},
   "source": [
    "## Appels des fonctions et déroulé du programme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a7208fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialisation - Import sequence: 1500000it [00:55, 27028.19it/s]\n",
      "Initialisation - Import DC3 sens: 100%|████████████████████████████████████████████████| 15/15 [00:18<00:00,  1.20s/it]\n",
      "Initialisation - Import DC3 anti-sens: 100%|███████████████████████████████████████████| 15/15 [00:16<00:00,  1.07s/it]\n",
      "Initialisation - Listes annexes chromosome brin sens: 100%|████████████████████████████| 15/15 [00:32<00:00,  2.17s/it]\n",
      "Initialisation - Listes annexes chromosome brin antisens: 100%|████████████████████████| 15/15 [00:38<00:00,  2.55s/it]\n",
      "Main - Read n°: 100%|███████████████████████████████████████████████████████████| 5000/5000 [13:24:28<00:00,  9.65s/it]\n"
     ]
    }
   ],
   "source": [
    "# On donne la possibilité de continuer un mapping déja existant (au cas où le mapping serait trop long par exemple):\n",
    "Continue = False\n",
    "\n",
    "if Continue == False :\n",
    "    # On initialise le fichier de sauvegarde des résultats\n",
    "    with open(\"result.txt\", 'w') as f: # On ouvre le fichier résultat\n",
    "        f.write(\"Name_seq\" + \"\\t\" + \"\\t\" + \"Find ?\" + \"\\t\" + \"Where : n° chromosome brin : start\" + \"\\n\") # On écrit le header\n",
    "else : # On reprend depuis la position arrêté, changement manuel actuellement mais possibilité d'automatiser en récupérant le nombre de ligne dans le fichier résultat\n",
    "    start = 200000 # Attention mettre la séquence de départ et non le n° du kmer (différent de la version de base !)\n",
    "\n",
    "# On récupère la séquence du génome, chaque chromose étant compartimenté dans la liste\n",
    "list_genom = genome_import() \n",
    "\n",
    "# On crée le brin inverse complémentaire du génome :\n",
    "list_genom_inv = []\n",
    "for data in list_genom :\n",
    "    genom = Seq(data[0])\n",
    "    genom = genom.reverse_complement()\n",
    "    list_genom_inv.append([str(genom), data[1] + \" : compl inv\"])\n",
    "\n",
    "# On récupère les reads obtenu lors du séquençage et on les découpes, chaque élément de la liste correspond à 1 kmer et num le nombre de kmer par séquence\n",
    "list_reads, num = reads_import_cuts(k)\n",
    "\n",
    "# On calcule et incorpore les DC3 aux listes\n",
    "\n",
    "if by_DC3 == True : # Par calcul\n",
    "    # Brin sens\n",
    "    for i in tqdm(range(len(list_genom)), desc = \"Initialisation - Calcul DC3 sens\") :\n",
    "        data = DC3(list_genom[i][0] + \"$\")\n",
    "        list_genom[i].append(data)\n",
    "    # Brin anti-sens\n",
    "    for i in tqdm(range(len(list_genom_inv)), desc = \"Initialisation - Calcul DC3 anti-sens\") :\n",
    "        data = DC3(list_genom_inv[i][0] + \"$\")\n",
    "        list_genom_inv[i].append(data)\n",
    "    \n",
    "else : # Par import\n",
    "    # Brin sens\n",
    "    for i in tqdm(range(len(list_genom)) ,desc = \"Initialisation - Import DC3 sens\") :\n",
    "        filename1 = \"DC3_chrom\"\n",
    "        filename3 = \".txt\"\n",
    "        filename = filename1 + str(i+1) + filename3\n",
    "\n",
    "        list_genom[i].append(import_DC3(filename))\n",
    "    # Brin anti-sens\n",
    "    for i in tqdm(range(len(list_genom)) ,desc = \"Initialisation - Import DC3 anti-sens\") :\n",
    "        filename1 = \"DC3_chrom\"\n",
    "        filename3 = \".txt\"\n",
    "        filename = filename1 + str(i+1) + \"_inv\" + filename3\n",
    "\n",
    "        list_genom_inv[i].append(import_DC3(filename))\n",
    "\n",
    "# On calcule la bwt, les index et les sommes pour chaque chromosome et on stocke en liste :  \n",
    "list_bwt = []\n",
    "list_index = []\n",
    "list_sum = []\n",
    "for i in tqdm(range(len(list_genom)), desc = \"Initialisation - Listes annexes chromosome brin sens\") : # Brin sens\n",
    "    bwt = BWT(list_genom[i][0] + \"$\",list_genom[i][2])\n",
    "    list_bwt.append(bwt)\n",
    "    ##initialisation de l'alphabet, de l'index et du compteur total de char\n",
    "    L = list(bwt)\n",
    "    alphabet = ['$','A','C','G','T']\n",
    "    index = []\n",
    "    char_index = {}\n",
    "    for char in L:\n",
    "        if char not in char_index: \n",
    "            char_index[char] = 0\n",
    "        index.append(char_index[char])\n",
    "        char_index[char] += 1\n",
    "    total = Counter(list_genom[i][0] + \"$\")\n",
    "    som = 0\n",
    "    somme = []\n",
    "    for char in alphabet:\n",
    "        som += total[char]\n",
    "        somme.append((char,som))\n",
    "    list_sum.append(somme)\n",
    "    list_index.append(index)\n",
    "\n",
    "for i in tqdm(range(len(list_genom_inv)), desc = \"Initialisation - Listes annexes chromosome brin antisens\") : # Brin anti-sens\n",
    "    bwt = BWT(list_genom_inv[i][0] + \"$\",list_genom_inv[i][2])\n",
    "    list_bwt.append(bwt)\n",
    "    ##initialisation de l'alphabet, de l'index et du compteur total de char\n",
    "    L = list(bwt)\n",
    "    alphabet = ['$','A','C','G','T']\n",
    "    index = []\n",
    "    char_index = {}\n",
    "    for char in L:\n",
    "        if char not in char_index: \n",
    "            char_index[char] = 0\n",
    "        index.append(char_index[char])\n",
    "        char_index[char] += 1\n",
    "    total = Counter(list_genom_inv[i][0] + \"$\")\n",
    "    som = 0\n",
    "    somme = []\n",
    "    for char in alphabet:\n",
    "        som += total[char]\n",
    "        somme.append((char,som))\n",
    "    list_sum.append(somme)\n",
    "    list_index.append(index)\n",
    "\n",
    "# On rentre dans l'analyse des données maintenant que les préparations du programme sont terminées :\n",
    "for reads in tqdm(range(start, int(len(list_reads)/num)), desc = \"Main - Read n°\") :\n",
    "    mapp_list = [] # On crée/vide la liste pour chaque séquence\n",
    "    # On mappe :\n",
    "    for genom in range(len(list_genom)) : # On merge les deux cas (sens et anti-sens) !\n",
    "        for kmer in range(num) :\n",
    "            pos_in_l = reads * num + kmer # On calcule la position à laquelle on se trouve dans la liste des reads\n",
    "            mapp_list.append([list_reads[pos_in_l][2], k_positioning(list_genom[genom][0] + \"$\", list_reads[pos_in_l][0], \n",
    "                                                                     list_bwt[genom], list_genom[genom][2], list_index[genom],\n",
    "                                                                     list_sum[genom])])\n",
    "            mapp_list.append([list_reads[pos_in_l][2], k_positioning(list_genom_inv[genom][0] + \"$\", list_reads[pos_in_l][0], \n",
    "                                                                     list_bwt[genom + 15], list_genom_inv[genom][2], \n",
    "                                                                     list_index[genom + 15], list_sum[genom + 15])])\n",
    "    # On crée la liste pour la liaison des kmers :\n",
    "    list_liaison = []\n",
    "    \n",
    "    for kmer in range(num) :\n",
    "        list_lia_temp = []\n",
    "        for all_gen in range(len(list_genom)) :\n",
    "            list_lia_temp.append(mapp_list[2*num*all_gen + kmer*2])\n",
    "            list_lia_temp.append(mapp_list[2*num*all_gen + kmer*2 + 1])\n",
    "        list_liaison.append([list_reads[reads * num + kmer][1], list_reads[reads * num + kmer][2], list_lia_temp])\n",
    "        \n",
    "    # On lie les kmers :\n",
    "    result = prepare_reads(list_liaison, k, num)\n",
    "    \n",
    "    # On écrit les résultats dans le fichier :\n",
    "    export_result(result)\n",
    "    \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4be590",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
