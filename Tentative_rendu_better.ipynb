{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4468d29f",
   "metadata": {},
   "source": [
    "## Partie Code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81d25d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO # Permet l'import de la fonction parse\n",
    "from Bio.Seq import Seq # Permet la transformation en complémentaire inverse\n",
    "from Bio.SeqIO.QualityIO import FastqGeneralIterator # Permet un parse plus rapide lorsque beaucoup de séquences (fastaq uniquement sinon voir site biopython pour fasta)\n",
    "import functools as ft # Permet de regrouper des listes pour radix sort\n",
    "from collections import Counter # Demander à Erwan\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm # Permet d'estimer le temps d'éxécution sur un boucle\n",
    "from datetime import datetime # Permet de comparer la vitesse de 2 programmes \n",
    "import os # Gestion des chemins\n",
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d402b8",
   "metadata": {},
   "source": [
    "### Fonctions d'import des données :\n",
    "\n",
    "Complexité des algorithms : linéaire en temps avec le nombre d'éléments à importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee27be11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_DC3(filename) :\n",
    "    \"\"\"\n",
    "    Fonction qui importe depuis un fichier texte la table des suffixes du génome par DC3 et la stocke dans une liste\n",
    "    \"\"\"\n",
    "    filename = \"DC3_save/\" + filename\n",
    "    with open(filename, 'r') as f:\n",
    "        text = f.readline()\n",
    "        data = text.split(\" \")[:-1]\n",
    "        for i in range(len(data)) :\n",
    "            data[i] = int(data[i])\n",
    "        return(data)\n",
    "    \n",
    "def genome_import() :\n",
    "    \"\"\"\n",
    "    Fonction qui importe depuis un fichier fasta la séquence du génome dans une liste contenant [\"seq\", \"n°k\"]\n",
    "    \"\"\"\n",
    "    list_genom=[]\n",
    "    for record in SeqIO.parse(\"GCF_000002765.5_GCA_000002765_genomic.fna\",\"fasta\"):\n",
    "        list_genom.append([str(record.seq).upper(),record.description[-14:]]) # attention le marquage est à changer pour la dernière séquence\n",
    "    \n",
    "    return list_genom\n",
    "    \n",
    "def reads_import_cuts(k) :\n",
    "    \"\"\"\n",
    "    Fonction qui importe depuis un fichier fasta les séquences des reads et les coupes en les rangeant\n",
    "    dans une liste contenant [\"seq\", \"nom\", \"n°kmer\"]\n",
    "    \n",
    "    Entrée : k, int : longueur du kmer\n",
    "    \n",
    "    Sortie : list_reads : liste de tous les read découpés en kmers\n",
    "    \"\"\"\n",
    "    list_reads=[]\n",
    "    with open(\"single_Pfal_dat.fq\") as in_handle:\n",
    "        for title, seq, qual in tqdm(FastqGeneralIterator(in_handle), desc = \"Initialisation - Import sequence\"):\n",
    "            i = 1    # Incrémenteur du nombre de k-mer\n",
    "            while len(seq) >= 1 : # On parcoure toute la séquence\n",
    "                if len(seq) > k : # Cas où le k-mer est entier\n",
    "                    list_reads.append([str(seq[0:k]).upper(),title, i])\n",
    "                    i += 1\n",
    "                    seq = seq[k:]\n",
    "                else : # Cas où le dernier k-mer n'est pas entier\n",
    "                    list_reads.append([str(seq).upper(),title, i])\n",
    "                    seq = \"\"\n",
    "                    i += 1 # Pour avoir le bon nombre de kmer s'il en reste un dernier\n",
    "            \n",
    "    return list_reads, i-1 # i-1 car on incrémente après avoir annoté"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99e14e4",
   "metadata": {},
   "source": [
    "### Fonction pour la table des suffixes (DC3)\n",
    "\n",
    "Complexité des algorithms : linéaire avec la longueur de la séquence pour DC3 et avec la taille de la liste pour les autres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd68c649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(arr):\n",
    "    \"\"\"\n",
    "    Nécessaire pour le radix sort, je te le laisse Erwan\n",
    "    \"\"\"\n",
    "    return ft.reduce(lambda x, y: x + y, arr)\n",
    "\n",
    "def counting_sort(array,digit,p): \n",
    "    \"\"\"\n",
    "    Nécessaire pour le radix sort, je te le laisse Erwan\n",
    "    \"\"\"\n",
    "    ##The counting sort is a stable sort used in the radic sort\n",
    "    ##here the counting sort needs to be adapted to look at only one digit of each number (for radix)\n",
    "    ##we also added the parameter p to be able to read the triplets (more info below)\n",
    "    ##1) since we only sort single digits, the max will always be smaller than 10\n",
    "    ##2) create count index (that will have the cumulative index in the end)\n",
    "    count_list = [[]for i in range(10)]\n",
    "    for tpl in array :\n",
    "        n_uplet = tpl[0]##we take the first element of the tuple, the n-uplet\n",
    "        num = n_uplet[p] // digit ##we cut off the digits to the right by getting the quotient of the euclidian division\n",
    "        ##p is the index of the number studied in the triplet\n",
    "        count_list[num%10].append(tpl)##we cut off the digits to the left by getting the remainder of the euclidian division\n",
    "    arr_ord = flatten(count_list)\n",
    "\n",
    "    for i in range(len(array)):##we change the base array to allow the radix sort to loop easily\n",
    "        array[i] = arr_ord[i]\n",
    "        \n",
    "def radix_sort(array,p):\n",
    "    \"\"\"\n",
    "    Prend en entrée un tableau de valeur de valeur et le trie en foncion de la première composante\n",
    "    selon l'algorithm du radix sort\n",
    "    \n",
    "    Entrée : array à trier\n",
    "             p : nombre de cases à trier p-uplets\n",
    "    \n",
    "    Sortie : array trié\n",
    "    \"\"\"\n",
    "    ##Here the radix sort is modified to work with the triplet list sent by the DC3\n",
    "    ##The code is not flexible enough to compute all characters in the ascii table, but it's enough for the use needed\n",
    "    ##1) we search for the max in the nuplets\n",
    "    mx = (max(array)[0])[0]+1\n",
    "    if p != 3 : ##we take max = 100 because A T C G are all below 100 in ascii code\n",
    "        for tpl in array:\n",
    "            n_uplet = tpl[0]\n",
    "            if n_uplet[-1] > mx :\n",
    "                mx = n_uplet[-1]+1\n",
    "    '''##2) to know how many loops we have to do, we will use a variable to represent,\n",
    "    the digit we are currently in'''\n",
    "    for i in reversed(range(0,p)):\n",
    "        digit = 1 ##starts at one for units\n",
    "        while mx - digit > 0 :##when all the digits are checked, digit will be greater than the maximum\n",
    "            counting_sort(array,digit,i)\n",
    "            digit *= 10 ##digit will go to the tens, the hundreds, the thousands...\n",
    "            \n",
    "def DC3(S, P_12_base = []) :\n",
    "    \"\"\"\n",
    "    Create the suffix array from DC3 algorithm, could be recursive if needed\n",
    "    \n",
    "    Args:\n",
    "        S (str): string\n",
    "        P_12_base : store P1+2 from recursion to map correctly recursivity\n",
    "    \n",
    "    Return:\n",
    "        index_012 : suffix array of S\n",
    "        order_12 : order of the next recursion to map correctly recursivity\n",
    "    \"\"\"\n",
    "    \n",
    "    DC3_table = np.zeros((3,len(S) + 3), dtype=int) # Les caractères sentinelles sont déja là !\n",
    "    \"\"\"\n",
    "    Table de DC3 qui contient en chaque ligne : \n",
    "    Ligne 0 : indice du caractère\n",
    "    Ligne 1 : conversion du caractère en nombre\n",
    "    Ligne 2 : Ordre de l'indice du caractère\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(len(S) + 3) :\n",
    "            DC3_table[0][i] =  i # On remplace le caractère par son code Ascii\n",
    "    \n",
    "    # String conversion : !!!!! à n'executer que lors de la première récursion !!!!!\n",
    "    if type(S) == str :\n",
    "        S_l = [*S] # On sépare caractère par caractère : \"ATGC\" devient [\"A\",\"T\",\"G\",\"C\"]\n",
    "        for i in range(len(S_l)) :\n",
    "            DC3_table[1][i] =  ord(S_l[i]) # On rempli le caractère par son code Ascii dans la table\n",
    "    else :\n",
    "         for i in range(len(S)) :\n",
    "            DC3_table[1][i] =  S[i] # Cas où l'on rentre dans la boucle une deuxième fois ou plus, pas de conversion\n",
    "    \"\"\"\n",
    "    # Cas où la chaine n'est composé que d'une seule lettre : trivial car DC3 = ordre des indices en décroissant\n",
    "    equal = True\n",
    "    for i in range(len(S)) :\n",
    "        if DC3_table[1][0] != DC3_table[1][i] :\n",
    "            equal = False\n",
    "            break # On teste si la chaine n'est composé que d'une seule lettre\n",
    "    if equal == True :\n",
    "         return [*range(len(S)-1,-1,-1)]\n",
    "    \"\"\"\n",
    "    \n",
    "    # On crée P0, P1, P2 et P1+P2 :    \n",
    "    P0 = [*range(0,len(S)+1,3)] \n",
    "    P1 = [*range(1,len(S)+1,3)]\n",
    "    P2 = [*range(2,len(S)+1,3)]\n",
    "    \n",
    "    P_12 = P1 + P2\n",
    "    \n",
    "\n",
    "    #Obtention des triplets à partir de P1+P2 :\n",
    "    R_12 = []\n",
    "    for val in P_12 :\n",
    "        R_12.append([list(DC3_table[1][val:val+3]), val])\n",
    "    \n",
    "    radix_sort(R_12,3) # On trie les triplets\n",
    "\n",
    "    index_12 = [] # Liste des indexes de R12 trié\n",
    "    order_count = 1 # Compteur pour remplir l'ordre\n",
    "    recur = False # Etat de la récursion tourné True si on a des égalités d'ordre\n",
    "    for j in range(len(R_12)) : # On parcours tous les triplets triés\n",
    "        index_12.append(R_12[j][1]) # ... pour lui attribuer son index depuis P_12\n",
    "        DC3_table[2][R_12[j][1]] = order_count # Et on ajoute l'ordre dans la table\n",
    "        if j < len(R_12)-1 :\n",
    "            if R_12[j][0] != R_12[j+1][0] : # On teste l'égalité des triplets pour mettre l'ordre\n",
    "                order_count += 1\n",
    "            else :\n",
    "                recur = True # On a égalité, donc on doit relancer l'algorithme à la fin des for\n",
    "        else :\n",
    "            order_count += 1\n",
    "\n",
    "    if recur == True :\n",
    "        new_S = [] # On crée T' la séquence des orders suivant l'ordre de P12\n",
    "        for l in P_12 :\n",
    "            new_S.append(DC3_table[2][l])\n",
    "        index_012 = DC3(new_S, P_12) # On doit récupérer ces deux paramètres sinon ça marche pas\n",
    "        index_12 = []\n",
    "        for ind,val in index_012 :\n",
    "            DC3_table[2][ind] = val\n",
    "            index_12.append(ind)\n",
    "    \n",
    "    R_0 = [] # On crée la dernière partie à trier\n",
    "    for val in P0 :\n",
    "        R_0.append([[int(DC3_table[1][val]), DC3_table[2][val + 1]], val]) # On crée R0 avec son indice\n",
    "    \n",
    "    \n",
    "    radix_sort(R_0,2)\n",
    "    \n",
    "    index_0 = [] # Liste des indexes de R0 trié\n",
    "    for k in range(len(R_0)) : # On parcours tous les doublets triés\n",
    "       index_0.append(R_0[k][1]) # On récupère l'indice\n",
    "    \n",
    "    index_012 = [] # On crée l'index final en ordonant 0 et 1,2\n",
    "    i_0 = 0\n",
    "    i_12 = 0\n",
    "    \n",
    "    index_12_dict = {}\n",
    "    for i in range(len(index_12)) :\n",
    "        index_12_dict[index_12[i]] = i\n",
    "    \n",
    "    while (i_0 < len(index_0) and i_12 < len(index_12)) : # On prends tout les éléments : on vide index 0 ou 12\n",
    "        val_i0 = index_0[i_0]\n",
    "        val_i12 = index_12[i_12]\n",
    "        \n",
    "        if DC3_table[1][val_i0] > DC3_table[1][val_i12] : # Cas où index 12 arrive avant index 0\n",
    "            index_012.append(index_12[i_12])\n",
    "            i_12 += 1\n",
    "        elif DC3_table[1][val_i0] < DC3_table[1][val_i12] : # Cas où index 0 arrive avant index 12\n",
    "            index_012.append(index_0[i_0])\n",
    "            i_0 += 1\n",
    "        else : # Cas d'égalité sur l'indice : si les 2 indexes renvoient le même nombre \n",
    "            if index_12[i_12] % 3 == 1 :\n",
    "                if index_12_dict[val_i0 + 1] > index_12_dict[val_i12 + 1] : # Cas où index 12 au deuxième terme arrive avant index 0 au deuxième terme\n",
    "                    index_012.append(index_12[i_12])\n",
    "                    i_12 += 1\n",
    "                else : # Cas où index 0 au deuxième terme arrive avant index 12 au deuxième terme\n",
    "                    index_012.append(index_0[i_0])\n",
    "                    i_0 += 1\n",
    "            else :\n",
    "                if DC3_table[1][val_i0 + 1] > DC3_table[1][val_i12 + 1] : # On teste dabord cas où index 12 + 1 arrive avant index 0 + 1\n",
    "                    index_012.append(index_12[i_12])\n",
    "                    i_12 += 1\n",
    "                elif DC3_table[1][val_i0 + 1] < DC3_table[1][val_i12 + 1] : # Cas où index 0 + 1 arrive avant index 12 + 1\n",
    "                    index_012.append(index_0[i_0])\n",
    "                    i_0 += 1\n",
    "                elif index_12_dict[val_i0 + 2] > index_12_dict[val_i12 + 2] : # Cas où index 12 au deuxième terme arrive avant index 0 au troisième terme\n",
    "                    index_012.append(index_12[i_12])\n",
    "                    i_12 += 1\n",
    "                else : # Cas où index 0 au troisième terme arrive avant index 12 au deuxième terme\n",
    "                    index_012.append(index_0[i_0])\n",
    "                    i_0 += 1\n",
    "    \n",
    "    index_012.extend(index_12[i_12:]) # Si 1 des deux index est encore plein, on ajoute son contenu\n",
    "    index_012.extend(index_0[i_0:])\n",
    "\n",
    "    if int(DC3_table[1][index_012[0]]) == 0 : # On enlève le terme sentinel s'il est présent\n",
    "        index_012 = index_012[1:]\n",
    "\n",
    "    if len(P_12_base) > 0 : # Mapping sur recursion -1 si existe\n",
    "        new_index_012 = []\n",
    "        for n in range(len(index_012)) :\n",
    "            new_index_012.append([P_12_base[index_012[n]], n])\n",
    "        index_012 = new_index_012\n",
    "   \n",
    "\n",
    "    return index_012 # Retourne le suffix array si dernière récursion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51519cc",
   "metadata": {},
   "source": [
    "### Fonctions de mapping :\n",
    "\n",
    "Complexité des algorithms : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8919d6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BWT(text,suffix_table):\n",
    "    \"\"\"\n",
    "    Compute the BWT from the suffix table\n",
    "\n",
    "    Args:\n",
    "        T (str): string\n",
    "        end_of_string (char): end of string character to append\n",
    "\n",
    "    Return:\n",
    "        bwt (str): BWT\n",
    "    \"\"\"\n",
    "    bwt = \"\"\n",
    "    sf_tab = suffix_table\n",
    "    for i in range(len(sf_tab)):\n",
    "        crt = sf_tab[i]\n",
    "        bwt += text[crt-1]\n",
    "    return(bwt)\n",
    "\n",
    "def pattern_matching_BWT(S,pattern,bwt,index,somme):\n",
    "    \"\"\"\n",
    "    Search a pattern in a String using the BWT\n",
    "\n",
    "    Args:\n",
    "        S (str): string\n",
    "        pattern (str): pattern\n",
    "        bwt : the bwt of the text (to not compute it each time)\n",
    "\n",
    "    Return:\n",
    "        bool: true if the pattern is in the string\n",
    "        int : position of the first occurence of the pattern in the ordered text\n",
    "        int : position of the last occurence of the pattern in the ordered text\n",
    "    \"\"\"\n",
    "    pattern_in_S = False\n",
    "    L = list(bwt)\n",
    "    lpattern = list(pattern)\n",
    "    start_string = -1\n",
    "    end_string = -1\n",
    "    e = 0\n",
    "    f = len(L)\n",
    "    ##init des valeurs utiles pour la substring search\n",
    "    i = len(lpattern)-1\n",
    "    X = lpattern[i]\n",
    "    for tpl in somme :\n",
    "        if tpl[0]<X:\n",
    "            e = tpl[1]+1 ##donne place du premier char dans la liste ordonnée\n",
    "        if tpl[0]==X:\n",
    "            f = tpl[1]-1 ##donne place du dernier char\n",
    "\n",
    "    while e < f and i > 0 :\n",
    "        X = lpattern[i]\n",
    "        Y = lpattern[i-1]\n",
    "        suite_impos = True\n",
    "        r = e\n",
    "        s = f\n",
    "        for u in range(r,s+1):\n",
    "            if(suite_impos==False):##we use the boolean to exit the loop early\n",
    "                break\n",
    "            if(L[u]==Y):\n",
    "                suite_impos= False\n",
    "                prev = 0\n",
    "                idx = index[u]\n",
    "                for tpl in somme :\n",
    "                    if tpl[0]<Y:\n",
    "                        prev = tpl[1]\n",
    "                e = prev + idx ##car l'index commence à 1 et non 0\n",
    "                start_string = e\n",
    "\n",
    "        char_found = False\n",
    "        for u in reversed(range(r,s+1)):\n",
    "            if(char_found or suite_impos):\n",
    "                break\n",
    "            if(L[u]==Y):\n",
    "                char_found = True\n",
    "                prev = 0\n",
    "                idx = index[u]\n",
    "                for tpl in somme :\n",
    "                    if tpl[0]<Y:\n",
    "                        prev = tpl[1]\n",
    "                f = prev + idx ##car l'index commence à 1 et non 0\n",
    "                end_string = f\n",
    "        if suite_impos :## this will stop the loop if no char has been found in the previous one\n",
    "            break\n",
    "        i -= 1\n",
    "    if suite_impos:\n",
    "        i = 0\n",
    "        pattern_in_S = False\n",
    "        return pattern_in_S,start_string,end_string\n",
    "    ##dans le cas où e = f, il faut vérifier que le reste du substring est bon\n",
    "    if i > 0 :\n",
    "        while i > 0 :\n",
    "            if L[e] != lpattern[i-1]:\n",
    "                break\n",
    "            prev = 0\n",
    "            idx = index[e]\n",
    "            start_string = e\n",
    "            end_string = e\n",
    "            for tpl in somme :\n",
    "                if tpl[0]<L[e]:\n",
    "                    prev = tpl[1]\n",
    "\n",
    "            e = prev + idx\n",
    "            i -= 1\n",
    "        idx = index[e]\n",
    "        start_string = e\n",
    "        end_string = e\n",
    "    if i < 1 :\n",
    "        pattern_in_S = True\n",
    "    return pattern_in_S,start_string,end_string\n",
    "\n",
    "def string_location(text,string,matches,suffix_table):\n",
    "    '''\n",
    "    Gives the position of each occurence of the substring in the text\n",
    "\n",
    "    Args :\n",
    "        text (string) : the text to search in\n",
    "        string (string) : the substring to be searched\n",
    "\n",
    "    Return :\n",
    "        ???\n",
    "    '''\n",
    "    result = matches\n",
    "    #print(result[1],result[2])\n",
    "    sft = suffix_table\n",
    "    list_occur = []\n",
    "    if result[0] == False :\n",
    "        #print(\"No occurence of the substring was found\")\n",
    "        list_occur.append(-1)\n",
    "    else :\n",
    "        for i in range(result[1],(result[2]+1)):\n",
    "            ##print(text[sft[i-1]-1],\"ici\")\n",
    "            idx = sft[i]\n",
    "            list_occur.append(idx)\n",
    "            #print(text[idx:idx+len(string)])\n",
    "    return(list_occur)\n",
    "\n",
    "def k_positioning(text,patt,bwt,suffix_table,index,somme):##permet d'obtenir la liste des positions\n",
    "    ##recuperation des positions des premiers et derniers patterns trouvés\n",
    "    mat = pattern_matching_BWT(text,patt,bwt,index,somme)\n",
    "    ##recupération et renvoi des positions de tout les patterns\n",
    "    return string_location(text,patt,mat,suffix_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211ad17d",
   "metadata": {},
   "source": [
    "### Fonctions d'assemblages des kmers \n",
    "\n",
    "Compexité des algorithms :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b57b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_reads(data,k):\n",
    "    \"\"\"\n",
    "    give_position of each read\n",
    "    Args:\n",
    "        data :List containing the treatment of kmer by mapping :\n",
    "        (kmer_seq, seq_name, kmer_pos, pos_genom_list)\n",
    "        kmer_seq : kmer,\n",
    "        seq_name : read containing the kmer,\n",
    "        kmer_pos : position of the kmer in the read,\n",
    "        pos_genom_list : possible positions of the kmer in the genom\n",
    "        k : length of kmers\n",
    "\n",
    "    Return:\n",
    "        ?\n",
    "    \"\"\"\n",
    "    read_pos=[]##creating a list of positions according to the read name with the position in the read\n",
    "    pres_list = []\n",
    "    for kmer in data :\n",
    "        for i in range(len(kmer)) :\n",
    "            read_pos.append(kmer[2])\n",
    "        \n",
    "    for j in range(len(read_pos[1])) :\n",
    "        list_for_k = [read_pos[0][j], read_pos[1][j], read_pos[2][j], read_pos[3][j],\n",
    "                      read_pos[4][j], read_pos[5][j], read_pos[6][j], read_pos[7][j],\n",
    "                      read_pos[8][j], read_pos[9][j]]\n",
    "        pres_list.append(list(link_reads(list_for_k,k)))\n",
    "    \n",
    "    return [data[0][0], pres_list]\n",
    "    \n",
    "    \n",
    "def link_reads (l_pos,k):\n",
    "    \"\"\"\n",
    "    Links the kmer of the reads\n",
    "    Args:\n",
    "        l_pos : list of tuple : (kmer_pos_read, kmer_pos_gen)\n",
    "        kmer_pos_read : position of the kmer in the read\n",
    "        kmer_pos_gen : possible position of the kmer in the genom\n",
    "        k : length of kmers\n",
    "    Return:\n",
    "\n",
    "    \"\"\"\n",
    "    valid=False # true if there is a valid position\n",
    "    val_pos=[] # list of valid starting position of the read in the genom\n",
    "    comment=\"\"\n",
    "    for i in l_pos[0][1] :# for each first position,we add the next part to see if it exists\n",
    "        cur_pos=1\n",
    "        if(cur_pos==len(l_pos)): # if there is only one position in the list\n",
    "            if (i!=-1): #if there is only a position -1 it returns False and no position\n",
    "                valid=True\n",
    "                val_pos.append(i)\n",
    "\n",
    "        else :  # if there is more than 1 element iiin the list\n",
    "            pos_gen=i+k # next position of the kmer of the read in the genom\n",
    "            while (pos_gen in l_pos[cur_pos][1]) : # we try to find the next kmer in the next list of position of kmer\n",
    "                cur_pos+=1\n",
    "                if(cur_pos==len(l_pos)): # when there is the whole read in the genom\n",
    "                    valid=True\n",
    "                    val_pos.append(i)# to return the position of the read(s) in the genom\n",
    "                    break\n",
    "                else :\n",
    "                    pos_gen+=k\n",
    "    if(valid==False):\n",
    "        for i in l_pos[0][1] :# for each first position,we look at the last kmer to see if it can correpond with the genom but with mutation between\n",
    "            cur_pos=1\n",
    "            if(cur_pos!=len(l_pos)):   # if there is more than 1 element in the list\n",
    "                pos_gen=i+k*(len(l_pos)-1) #  position of the last kmer of the read in the genom\n",
    "                if (pos_gen in l_pos[-1][1]) : # we try to find the last position in the last element of the list\n",
    "                        comment+=\"possible mutation\"\n",
    "                        val_pos.append(i)# to return the position of the read(s) in the genom\n",
    "                        valid = True\n",
    "                        break\n",
    "\n",
    "    return (valid, val_pos,comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79c3e7e",
   "metadata": {},
   "source": [
    "### Fonction du fichier de sortie du programme\n",
    "\n",
    "Complexité des algorithms : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f3b7760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_result(result, list_genom) :\n",
    "    \"\"\"\n",
    "    Ecrit les résultats obtenus du mapping pour chaque read dans un fichier texte\n",
    "    \"\"\"\n",
    "    longueur_read = 100 #Ici on sait que c'est 100, changer en detection automatique si j'ai le temps\n",
    "    with open(\"result.txt\", 'a') as f: # On ouvre le fichier résultat\n",
    "            line = result[0]\n",
    "            find = False\n",
    "            pos = \"\"\n",
    "            for j in range(len(result[1][1])) :\n",
    "                if result[1][j][0] == True :\n",
    "                    find = True\n",
    "                    for el in result[1][j][1] :\n",
    "                        if j+1 % 2 == 0 :\n",
    "                            if result[1][j][2] == \"possible mutation\" :\n",
    "                                pos += str((j+1)/2) + \" - : \" + \"~\" + str(len(list_genom[(j+1)/2]) - longueur_read - el + 1 ) + \"\\t\"\n",
    "                            else :\n",
    "                                pos += str((j+1)/2) + \" - : \" + str(len(list_genom[(j+1)/2]) - longueur_read - el + 1 ) + \"\\t\"\n",
    "                        else :\n",
    "                            if result[1][j][2] == \"possible mutation\" :\n",
    "                                pos += str((j+2)/2) + \" + : \" + \"~\" + str(el + 1) + \"\\t\"\n",
    "                            else :\n",
    "                                pos += str((j+2)/2) + \" + : \" + str(el + 1) + \"\\t\"\n",
    "            if find == False :\n",
    "                line += \"\\tFalse\"\n",
    "            else :\n",
    "                line += \"\\tTrue\" + \"\\t\" + pos\n",
    "            f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33a1f78",
   "metadata": {},
   "source": [
    "## Appels des fonctions et déroulé du programme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a7208fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialisation - Import sequence: 1500000it [00:41, 36219.90it/s]\n",
      "Initialisation - Import DC3 sens: 100%|████████████████████████████████████████████████| 15/15 [00:14<00:00,  1.07it/s]\n",
      "Initialisation - Import DC3 anti-sens: 100%|███████████████████████████████████████████| 15/15 [00:14<00:00,  1.04it/s]\n",
      "Initialisation - Listes annexes chromosome brin sens: 100%|████████████████████████████| 15/15 [00:33<00:00,  2.23s/it]\n",
      "Initialisation - Listes annexes chromosome brin antisens: 100%|████████████████████████| 15/15 [00:34<00:00,  2.30s/it]\n",
      "Main - Read n°:   0%|                                                         | 1/1500000 [00:08<3708:29:45,  8.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Main - Read n°:   0%|                                                         | 2/1500000 [00:17<3665:59:31,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Main - Read n°:   0%|                                                         | 3/1500000 [00:26<3657:42:12,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Main - Read n°:   0%|                                                         | 4/1500000 [00:35<3785:55:07,  9.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Main - Read n°:   0%|                                                         | 5/1500000 [00:44<3765:09:39,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Main - Read n°:   0%|                                                         | 6/1500000 [00:53<3734:13:54,  8.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Main - Read n°:   0%|                                                         | 7/1500000 [01:02<3701:54:42,  8.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Main - Read n°:   0%|                                                         | 8/1500000 [01:10<3653:29:07,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Main - Read n°:   0%|                                                         | 8/1500000 [02:19<7261:00:53, 17.43s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13484\\2183025611.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;31m# On lie les kmers :\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_reads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_liaison\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;31m# On append les résultats :\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13484\\674629131.py\u001b[0m in \u001b[0;36mprepare_reads\u001b[1;34m(data, k)\u001b[0m\n\u001b[0;32m     25\u001b[0m                       \u001b[0mread_pos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mread_pos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mread_pos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mread_pos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                       read_pos[8][j], read_pos[9][j]]\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mpres_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink_reads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_for_k\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpres_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13484\\674629131.py\u001b[0m in \u001b[0;36mlink_reads\u001b[1;34m(l_pos, k)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ml_pos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;31m# for each first position,we add the next part to see if it exists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mcur_pos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_pos\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml_pos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# if there is only one position in the list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#if there is only a position -1 it returns False and no position\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m                 \u001b[0mvalid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "k = 10 # On défini k, la longueur de chaque kmers\n",
    "by_DC3 = False # True : on calcule la DC3 depuis les données, False : on la récupère depuis le fichier de sauvegarde\n",
    "start = 0 # On commence par le premier read sinon modifier ligne 12\n",
    "\n",
    "# On donne la possibilité de continuer un mapping déja existant :\n",
    "Continue = False\n",
    "\n",
    "if Continue == False :\n",
    "    # On initialise le fichier de sauvegarde des résultats\n",
    "    with open(\"result.txt\", 'w') as f: # On ouvre le fichier résultat\n",
    "        f.write(\"Name_seq\" + \"\\t\" + \"\\t\" + \"Find ?\" + \"\\t\" + \"Where : n° chromosome brin : start\" + \"\\n\") # On écrit le header\n",
    "else :\n",
    "    start = 200000 # Attention mettre la séquence de départ et non le kmer\n",
    "\n",
    "# On récupère la séquence du génome, chaque chromose étant compartimenté dans la liste\n",
    "list_genom = genome_import() \n",
    "\n",
    "# On crée le brin inverse complémentaire du génome :\n",
    "list_genom_inv = []\n",
    "for data in list_genom :\n",
    "    genom = Seq(data[0])\n",
    "    genom = genom.reverse_complement()\n",
    "    list_genom_inv.append([str(genom), data[1] + \" : compl inv\"])\n",
    "\n",
    "# On récupère les reads obtenu lors du séquençage et on les découpes, chaque élément de la liste correspond à 1 kmer et num le nombre de kmer par séquence\n",
    "list_reads, num = reads_import_cuts(k)\n",
    "\n",
    "# On calcule et incorpore les DC3 aux listes\n",
    "\n",
    "if by_DC3 == True :\n",
    "    # Brin sens\n",
    "    for i in tqdm(range(len(list_genom)), desc = \"Initialisation - Calcul DC3 sens\") :\n",
    "        data = DC3(list_genom[i][0] + \"$\")\n",
    "        list_genom[i].append(data)\n",
    "    # Brin anti-sens\n",
    "    for i in tqdm(range(len(list_genom_inv)), desc = \"Initialisation - Calcul DC3 anti-sens\") :\n",
    "        data = DC3(list_genom_inv[i][0] + \"$\")\n",
    "        list_genom_inv[i].append(data)\n",
    "    \n",
    "else :\n",
    "    # Brin sens\n",
    "    for i in tqdm(range(len(list_genom)) ,desc = \"Initialisation - Import DC3 sens\") :\n",
    "        filename1 = \"DC3_chrom\"\n",
    "        filename3 = \".txt\"\n",
    "        filename = filename1 + str(i+1) + filename3\n",
    "\n",
    "        list_genom[i].append(import_DC3(filename))\n",
    "    # Brin anti-sens\n",
    "    for i in tqdm(range(len(list_genom)) ,desc = \"Initialisation - Import DC3 anti-sens\") :\n",
    "        filename1 = \"DC3_chrom\"\n",
    "        filename3 = \".txt\"\n",
    "        filename = filename1 + str(i+1) + \"_inv\" + filename3\n",
    "\n",
    "        list_genom_inv[i].append(import_DC3(filename))\n",
    "\n",
    "list_bwt = []\n",
    "list_index = []\n",
    "list_sum = []\n",
    "# On calcule la bwt, les index et les sommes pour chaque chromosome et on stocke en liste :\n",
    "for i in tqdm(range(len(list_genom)), desc = \"Initialisation - Listes annexes chromosome brin sens\") :\n",
    "    bwt = BWT(list_genom[i][0] + \"$\",list_genom[i][2])\n",
    "    list_bwt.append(bwt)\n",
    "    ##initialisation de l'alphabet, de l'index et du compteur total de char\n",
    "    L = list(bwt)\n",
    "    alphabet = ['$','A','C','G','T']\n",
    "    index = []\n",
    "    char_index = {}\n",
    "    for char in L:\n",
    "        if char not in char_index: \n",
    "            char_index[char] = 0\n",
    "        index.append(char_index[char])\n",
    "        char_index[char] += 1\n",
    "    total = Counter(list_genom[i][0] + \"$\")\n",
    "    som = 0\n",
    "    somme = []\n",
    "    for char in alphabet:\n",
    "        som += total[char]\n",
    "        somme.append((char,som))\n",
    "    list_sum.append(somme)\n",
    "    list_index.append(index)\n",
    "\n",
    "for i in tqdm(range(len(list_genom_inv)), desc = \"Initialisation - Listes annexes chromosome brin antisens\") :\n",
    "    bwt = BWT(list_genom_inv[i][0] + \"$\",list_genom_inv[i][2])\n",
    "    list_bwt.append(bwt)\n",
    "    \n",
    "    ##initialisation de l'alphabet, de l'index et du compteur total de char\n",
    "    L = list(bwt)\n",
    "    alphabet = ['$','A','C','G','T']\n",
    "    index = []\n",
    "    char_index = {}\n",
    "    for char in L:\n",
    "        if char not in char_index: \n",
    "            char_index[char] = 0\n",
    "        index.append(char_index[char])\n",
    "        char_index[char] += 1\n",
    "    total = Counter(list_genom_inv[i][0] + \"$\")\n",
    "    som = 0\n",
    "    somme = []\n",
    "    for char in alphabet:\n",
    "        som += total[char]\n",
    "        somme.append((char,som))\n",
    "    list_sum.append(somme)\n",
    "    list_index.append(index)\n",
    "\n",
    "\n",
    "for reads in tqdm(range(start, int(len(list_reads)/num)), desc = \"Main - Read n°\") :\n",
    "    mapp_list = [] # On crée/vide la liste pour chaque séquence\n",
    "    # On mappe :\n",
    "    for genom in range(len(list_genom)) : # On merge les deux cas (sens et anti-sens) !\n",
    "        for kmer in range(num) :\n",
    "            pos_in_l = reads * num + kmer # On calcule la position à laquelle on se trouve dans la liste des reads\n",
    "            mapp_list.append([list_reads[pos_in_l][2], k_positioning(list_genom[genom][0] + \"$\", list_reads[pos_in_l][0], \n",
    "                                                                     list_bwt[genom], list_genom[genom][2], list_index[genom],\n",
    "                                                                     list_sum[genom])])\n",
    "            mapp_list.append([list_reads[pos_in_l][2], k_positioning(list_genom_inv[genom][0] + \"$\", list_reads[pos_in_l][0], \n",
    "                                                                     list_bwt[genom + 15], list_genom_inv[genom][2], \n",
    "                                                                     list_index[genom + 15], list_sum[genom + 15])])\n",
    "    # On crée la liste pour la liaison des kmers :\n",
    "    list_liaison = []\n",
    "    \n",
    "    for kmer in range(num) :\n",
    "        list_lia_temp = []\n",
    "        for all_gen in range(len(list_genom)) :\n",
    "            list_lia_temp.append(mapp_list[2*num*all_gen + kmer*2])\n",
    "            list_lia_temp.append(mapp_list[2*num*all_gen + kmer*2 + 1])\n",
    "        list_liaison.append([list_reads[reads * num + kmer][1], list_reads[reads * num + kmer][2], list_lia_temp])\n",
    "        \n",
    "    # On lie les kmers :\n",
    "    result = prepare_reads(list_liaison, k)\n",
    "    \n",
    "    # On append les résultats :\n",
    "    export_result(result, list_genom[1:-1])\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e73b316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
